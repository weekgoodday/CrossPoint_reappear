/home/zht/anaconda3/envs/py38torch19/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/zht/anaconda3/envs/py38torch19/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Use Adam
Start training epoch: (0/100)
Epoch (0), Batch(0/2189), loss: 19.032600, imid loss: 4.600020, imid1 loss: 5.713205, cmid0 loss: 8.719376
Epoch (0), Batch(200/2189), loss: 9.421889, imid loss: 2.940419, imid1 loss: 2.858906, cmid0 loss: 3.622564
Epoch (0), Batch(400/2189), loss: 8.253628, imid loss: 2.569515, imid1 loss: 2.313883, cmid0 loss: 3.370231
Epoch (0), Batch(600/2189), loss: 7.468741, imid loss: 2.320850, imid1 loss: 2.000019, cmid0 loss: 3.147872
Epoch (0), Batch(800/2189), loss: 6.886487, imid loss: 2.116120, imid1 loss: 1.787745, cmid0 loss: 2.982621
Epoch (0), Batch(1000/2189), loss: 6.431518, imid loss: 1.940811, imid1 loss: 1.644840, cmid0 loss: 2.845867
Epoch (0), Batch(1200/2189), loss: 6.068216, imid loss: 1.806358, imid1 loss: 1.530561, cmid0 loss: 2.731297
Epoch (0), Batch(1400/2189), loss: 5.764934, imid loss: 1.696183, imid1 loss: 1.437526, cmid0 loss: 2.631226
Epoch (0), Batch(1600/2189), loss: 5.503055, imid loss: 1.602981, imid1 loss: 1.361665, cmid0 loss: 2.538409
Epoch (0), Batch(1800/2189), loss: 5.281028, imid loss: 1.529982, imid1 loss: 1.293415, cmid0 loss: 2.457631
Epoch (0), Batch(2000/2189), loss: 5.089103, imid loss: 1.463522, imid1 loss: 1.233579, cmid0 loss: 2.392001
Train 0, loss: 4.934171
Linear Accuracy : 0.8780388978930308
==> Saving Best Model...
==> Saving...
Start training epoch: (1/100)
Epoch (1), Batch(0/2189), loss: 3.323501, imid loss: 1.100269, imid1 loss: 0.496310, cmid0 loss: 1.726921
Epoch (1), Batch(200/2189), loss: 3.049779, imid loss: 0.752279, imid1 loss: 0.669835, cmid0 loss: 1.627665
Epoch (1), Batch(400/2189), loss: 2.979500, imid loss: 0.718611, imid1 loss: 0.675304, cmid0 loss: 1.585585
Epoch (1), Batch(600/2189), loss: 2.909977, imid loss: 0.691664, imid1 loss: 0.672650, cmid0 loss: 1.545663
Epoch (1), Batch(800/2189), loss: 2.876471, imid loss: 0.686949, imid1 loss: 0.664546, cmid0 loss: 1.524976
Epoch (1), Batch(1000/2189), loss: 2.823380, imid loss: 0.673780, imid1 loss: 0.652946, cmid0 loss: 1.496654
Epoch (1), Batch(1200/2189), loss: 2.768939, imid loss: 0.657816, imid1 loss: 0.641590, cmid0 loss: 1.469533
Epoch (1), Batch(1400/2189), loss: 2.725370, imid loss: 0.648605, imid1 loss: 0.627285, cmid0 loss: 1.449480
Epoch (1), Batch(1600/2189), loss: 2.670610, imid loss: 0.636406, imid1 loss: 0.612213, cmid0 loss: 1.421991
Epoch (1), Batch(1800/2189), loss: 2.617941, imid loss: 0.625170, imid1 loss: 0.598746, cmid0 loss: 1.394025
Epoch (1), Batch(2000/2189), loss: 2.575704, imid loss: 0.615878, imid1 loss: 0.588314, cmid0 loss: 1.371512
Train 1, loss: 2.527464
Linear Accuracy : 0.8743922204213939
Start training epoch: (2/100)
Epoch (2), Batch(0/2189), loss: 2.172472, imid loss: 0.427352, imid1 loss: 0.512139, cmid0 loss: 1.232981
Epoch (2), Batch(200/2189), loss: 2.142618, imid loss: 0.493543, imid1 loss: 0.508431, cmid0 loss: 1.140644
Epoch (2), Batch(400/2189), loss: 2.084232, imid loss: 0.472742, imid1 loss: 0.489581, cmid0 loss: 1.121910
Epoch (2), Batch(600/2189), loss: 2.035509, imid loss: 0.461855, imid1 loss: 0.477259, cmid0 loss: 1.096395
Epoch (2), Batch(800/2189), loss: 1.997828, imid loss: 0.455340, imid1 loss: 0.468231, cmid0 loss: 1.074257
Epoch (2), Batch(1000/2189), loss: 1.974847, imid loss: 0.450953, imid1 loss: 0.457964, cmid0 loss: 1.065930
Epoch (2), Batch(1200/2189), loss: 1.945458, imid loss: 0.445320, imid1 loss: 0.450218, cmid0 loss: 1.049920
Epoch (2), Batch(1400/2189), loss: 1.917714, imid loss: 0.439483, imid1 loss: 0.443594, cmid0 loss: 1.034637
Epoch (2), Batch(1600/2189), loss: 1.897285, imid loss: 0.435231, imid1 loss: 0.440240, cmid0 loss: 1.021815
Epoch (2), Batch(1800/2189), loss: 1.873634, imid loss: 0.429947, imid1 loss: 0.433539, cmid0 loss: 1.010149
Epoch (2), Batch(2000/2189), loss: 1.851580, imid loss: 0.424209, imid1 loss: 0.426862, cmid0 loss: 1.000509
Train 2, loss: 1.835158
Linear Accuracy : 0.8853322528363047
==> Saving Best Model...
Start training epoch: (3/100)
Epoch (3), Batch(0/2189), loss: 1.888395, imid loss: 0.439272, imid1 loss: 0.471437, cmid0 loss: 0.977685
Epoch (3), Batch(200/2189), loss: 1.566458, imid loss: 0.359007, imid1 loss: 0.360693, cmid0 loss: 0.846758
Epoch (3), Batch(400/2189), loss: 1.563894, imid loss: 0.362912, imid1 loss: 0.352674, cmid0 loss: 0.848308
Epoch (3), Batch(600/2189), loss: 1.560389, imid loss: 0.360294, imid1 loss: 0.352046, cmid0 loss: 0.848049
Epoch (3), Batch(800/2189), loss: 1.555028, imid loss: 0.358551, imid1 loss: 0.348742, cmid0 loss: 0.847735
Epoch (3), Batch(1000/2189), loss: 1.538403, imid loss: 0.350927, imid1 loss: 0.348075, cmid0 loss: 0.839400
Epoch (3), Batch(1200/2189), loss: 1.526555, imid loss: 0.346945, imid1 loss: 0.346284, cmid0 loss: 0.833325
Epoch (3), Batch(1400/2189), loss: 1.505883, imid loss: 0.340794, imid1 loss: 0.342532, cmid0 loss: 0.822557
Epoch (3), Batch(1600/2189), loss: 1.481971, imid loss: 0.335184, imid1 loss: 0.337281, cmid0 loss: 0.809505
Epoch (3), Batch(1800/2189), loss: 1.472086, imid loss: 0.332300, imid1 loss: 0.336464, cmid0 loss: 0.803322
Epoch (3), Batch(2000/2189), loss: 1.459830, imid loss: 0.329331, imid1 loss: 0.334081, cmid0 loss: 0.796418
Train 3, loss: 1.451800
Linear Accuracy : 0.8824959481361426
Start training epoch: (4/100)
Epoch (4), Batch(0/2189), loss: 1.045406, imid loss: 0.198497, imid1 loss: 0.310325, cmid0 loss: 0.536583
Epoch (4), Batch(200/2189), loss: 1.347450, imid loss: 0.313327, imid1 loss: 0.303951, cmid0 loss: 0.730172
Epoch (4), Batch(400/2189), loss: 1.311993, imid loss: 0.299888, imid1 loss: 0.298945, cmid0 loss: 0.713160
Epoch (4), Batch(600/2189), loss: 1.294210, imid loss: 0.292769, imid1 loss: 0.299261, cmid0 loss: 0.702181
Epoch (4), Batch(800/2189), loss: 1.296688, imid loss: 0.296107, imid1 loss: 0.297028, cmid0 loss: 0.703553
Epoch (4), Batch(1000/2189), loss: 1.293304, imid loss: 0.296561, imid1 loss: 0.297705, cmid0 loss: 0.699038
Epoch (4), Batch(1200/2189), loss: 1.281306, imid loss: 0.295482, imid1 loss: 0.295566, cmid0 loss: 0.690258
Epoch (4), Batch(1400/2189), loss: 1.281985, imid loss: 0.297784, imid1 loss: 0.295132, cmid0 loss: 0.689068
Epoch (4), Batch(1600/2189), loss: 1.273504, imid loss: 0.294909, imid1 loss: 0.292962, cmid0 loss: 0.685632
Epoch (4), Batch(1800/2189), loss: 1.261598, imid loss: 0.291757, imid1 loss: 0.289962, cmid0 loss: 0.679879
Epoch (4), Batch(2000/2189), loss: 1.250073, imid loss: 0.289951, imid1 loss: 0.286372, cmid0 loss: 0.673750
Train 4, loss: 1.241462
Linear Accuracy : 0.8816855753646677
Start training epoch: (5/100)
Epoch (5), Batch(0/2189), loss: 0.699620, imid loss: 0.204587, imid1 loss: 0.126765, cmid0 loss: 0.368268
Epoch (5), Batch(200/2189), loss: 1.140270, imid loss: 0.271558, imid1 loss: 0.247208, cmid0 loss: 0.621503
Epoch (5), Batch(400/2189), loss: 1.158510, imid loss: 0.266633, imid1 loss: 0.259448, cmid0 loss: 0.632429
Epoch (5), Batch(600/2189), loss: 1.143671, imid loss: 0.264550, imid1 loss: 0.255664, cmid0 loss: 0.623457
Epoch (5), Batch(800/2189), loss: 1.129688, imid loss: 0.259242, imid1 loss: 0.250454, cmid0 loss: 0.619992
Epoch (5), Batch(1000/2189), loss: 1.125347, imid loss: 0.256809, imid1 loss: 0.251826, cmid0 loss: 0.616712
Epoch (5), Batch(1200/2189), loss: 1.117760, imid loss: 0.255342, imid1 loss: 0.248964, cmid0 loss: 0.613454
[34m[1mwandb[39m[22m: Network error resolved after 0:28:30.728909, resuming normal operation.
Epoch (5), Batch(1400/2189), loss: 1.109892, imid loss: 0.252773, imid1 loss: 0.248565, cmid0 loss: 0.608554
Epoch (5), Batch(1600/2189), loss: 1.104742, imid loss: 0.252266, imid1 loss: 0.247664, cmid0 loss: 0.604812
Epoch (5), Batch(1800/2189), loss: 1.102007, imid loss: 0.250739, imid1 loss: 0.248748, cmid0 loss: 0.602520
Epoch (5), Batch(2000/2189), loss: 1.096917, imid loss: 0.250004, imid1 loss: 0.247247, cmid0 loss: 0.599666
Train 5, loss: 1.092563
Linear Accuracy : 0.8869529983792545
==> Saving Best Model...
==> Saving...
Start training epoch: (6/100)
Epoch (6), Batch(0/2189), loss: 1.726125, imid loss: 0.384798, imid1 loss: 0.440467, cmid0 loss: 0.900860
Epoch (6), Batch(200/2189), loss: 1.049604, imid loss: 0.253671, imid1 loss: 0.223976, cmid0 loss: 0.571957
Epoch (6), Batch(400/2189), loss: 1.035069, imid loss: 0.245821, imid1 loss: 0.226960, cmid0 loss: 0.562287
Epoch (6), Batch(600/2189), loss: 1.026262, imid loss: 0.242626, imid1 loss: 0.222964, cmid0 loss: 0.560672
Epoch (6), Batch(800/2189), loss: 1.014207, imid loss: 0.239249, imid1 loss: 0.222036, cmid0 loss: 0.552922
Epoch (6), Batch(1000/2189), loss: 1.003550, imid loss: 0.235568, imid1 loss: 0.219805, cmid0 loss: 0.548177
Epoch (6), Batch(1200/2189), loss: 0.999185, imid loss: 0.233751, imid1 loss: 0.218344, cmid0 loss: 0.547091
Epoch (6), Batch(1400/2189), loss: 0.986554, imid loss: 0.229271, imid1 loss: 0.217738, cmid0 loss: 0.539545
Epoch (6), Batch(1600/2189), loss: 0.982137, imid loss: 0.228033, imid1 loss: 0.217610, cmid0 loss: 0.536493
Epoch (6), Batch(1800/2189), loss: 0.977861, imid loss: 0.226240, imid1 loss: 0.217237, cmid0 loss: 0.534385
Epoch (6), Batch(2000/2189), loss: 0.976422, imid loss: 0.225865, imid1 loss: 0.217809, cmid0 loss: 0.532748
Train 6, loss: 0.968149
Linear Accuracy : 0.8873581847649918
==> Saving Best Model...
Start training epoch: (7/100)
Epoch (7), Batch(0/2189), loss: 0.358084, imid loss: 0.124279, imid1 loss: 0.027749, cmid0 loss: 0.206055
Epoch (7), Batch(200/2189), loss: 0.871498, imid loss: 0.205123, imid1 loss: 0.204047, cmid0 loss: 0.462328
Epoch (7), Batch(400/2189), loss: 0.890091, imid loss: 0.210905, imid1 loss: 0.200183, cmid0 loss: 0.479003
Epoch (7), Batch(600/2189), loss: 0.903521, imid loss: 0.212914, imid1 loss: 0.205686, cmid0 loss: 0.484921
Epoch (7), Batch(800/2189), loss: 0.923056, imid loss: 0.212700, imid1 loss: 0.214491, cmid0 loss: 0.495865
Epoch (7), Batch(1000/2189), loss: 0.908730, imid loss: 0.208436, imid1 loss: 0.208916, cmid0 loss: 0.491378
Epoch (7), Batch(1200/2189), loss: 0.905554, imid loss: 0.208693, imid1 loss: 0.207527, cmid0 loss: 0.489333
Epoch (7), Batch(1400/2189), loss: 0.906389, imid loss: 0.210663, imid1 loss: 0.207737, cmid0 loss: 0.487989
Epoch (7), Batch(1600/2189), loss: 0.900122, imid loss: 0.207795, imid1 loss: 0.207293, cmid0 loss: 0.485034
Epoch (7), Batch(1800/2189), loss: 0.897225, imid loss: 0.207024, imid1 loss: 0.205361, cmid0 loss: 0.484840
Epoch (7), Batch(2000/2189), loss: 0.891523, imid loss: 0.205336, imid1 loss: 0.203824, cmid0 loss: 0.482362
Train 7, loss: 0.887523
Linear Accuracy : 0.8861426256077796
Start training epoch: (8/100)
Epoch (8), Batch(0/2189), loss: 1.100925, imid loss: 0.293833, imid1 loss: 0.443528, cmid0 loss: 0.363563
Epoch (8), Batch(200/2189), loss: 0.836247, imid loss: 0.201226, imid1 loss: 0.190630, cmid0 loss: 0.444391
Epoch (8), Batch(400/2189), loss: 0.817715, imid loss: 0.196708, imid1 loss: 0.183649, cmid0 loss: 0.437358
Epoch (8), Batch(600/2189), loss: 0.805660, imid loss: 0.191494, imid1 loss: 0.180247, cmid0 loss: 0.433918
Epoch (8), Batch(800/2189), loss: 0.798506, imid loss: 0.187088, imid1 loss: 0.180103, cmid0 loss: 0.431315
Epoch (8), Batch(1000/2189), loss: 0.798651, imid loss: 0.186540, imid1 loss: 0.180741, cmid0 loss: 0.431369
Epoch (8), Batch(1200/2189), loss: 0.795512, imid loss: 0.186444, imid1 loss: 0.178590, cmid0 loss: 0.430479
Epoch (8), Batch(1400/2189), loss: 0.796245, imid loss: 0.186613, imid1 loss: 0.178498, cmid0 loss: 0.431134
Epoch (8), Batch(1600/2189), loss: 0.801021, imid loss: 0.187489, imid1 loss: 0.180019, cmid0 loss: 0.433513
Epoch (8), Batch(1800/2189), loss: 0.805862, imid loss: 0.187573, imid1 loss: 0.182214, cmid0 loss: 0.436075
Epoch (8), Batch(2000/2189), loss: 0.802291, imid loss: 0.186844, imid1 loss: 0.181999, cmid0 loss: 0.433448
Train 8, loss: 0.797387
Linear Accuracy : 0.8893841166936791
==> Saving Best Model...
Start training epoch: (9/100)
Epoch (9), Batch(0/2189), loss: 0.650717, imid loss: 0.091247, imid1 loss: 0.148310, cmid0 loss: 0.411159
Epoch (9), Batch(200/2189), loss: 0.763568, imid loss: 0.175040, imid1 loss: 0.179221, cmid0 loss: 0.409307
Epoch (9), Batch(400/2189), loss: 0.764791, imid loss: 0.177665, imid1 loss: 0.172210, cmid0 loss: 0.414917
Epoch (9), Batch(600/2189), loss: 0.763116, imid loss: 0.177702, imid1 loss: 0.171379, cmid0 loss: 0.414035
Epoch (9), Batch(800/2189), loss: 0.752483, imid loss: 0.176725, imid1 loss: 0.168333, cmid0 loss: 0.407425
Epoch (9), Batch(1000/2189), loss: 0.752517, imid loss: 0.176510, imid1 loss: 0.168627, cmid0 loss: 0.407381
Epoch (9), Batch(1200/2189), loss: 0.748647, imid loss: 0.174757, imid1 loss: 0.167512, cmid0 loss: 0.406379
Epoch (9), Batch(1400/2189), loss: 0.747809, imid loss: 0.173770, imid1 loss: 0.168959, cmid0 loss: 0.405080
Epoch (9), Batch(1600/2189), loss: 0.748289, imid loss: 0.174596, imid1 loss: 0.168601, cmid0 loss: 0.405091
Epoch (9), Batch(1800/2189), loss: 0.745473, imid loss: 0.172900, imid1 loss: 0.168080, cmid0 loss: 0.404493
Epoch (9), Batch(2000/2189), loss: 0.742828, imid loss: 0.173041, imid1 loss: 0.167387, cmid0 loss: 0.402400
Train 9, loss: 0.742057
Linear Accuracy : 0.8950567260940032
==> Saving Best Model...
Start training epoch: (10/100)
Epoch (10), Batch(0/2189), loss: 0.695928, imid loss: 0.171704, imid1 loss: 0.106596, cmid0 loss: 0.417628
Epoch (10), Batch(200/2189), loss: 0.718180, imid loss: 0.172554, imid1 loss: 0.165600, cmid0 loss: 0.380026
Epoch (10), Batch(400/2189), loss: 0.702329, imid loss: 0.169402, imid1 loss: 0.154870, cmid0 loss: 0.378057
Epoch (10), Batch(600/2189), loss: 0.709277, imid loss: 0.172747, imid1 loss: 0.155126, cmid0 loss: 0.381403
Epoch (10), Batch(800/2189), loss: 0.713117, imid loss: 0.172226, imid1 loss: 0.157402, cmid0 loss: 0.383489
Epoch (10), Batch(1000/2189), loss: 0.714902, imid loss: 0.170732, imid1 loss: 0.160553, cmid0 loss: 0.383618
Epoch (10), Batch(1200/2189), loss: 0.714640, imid loss: 0.170382, imid1 loss: 0.160282, cmid0 loss: 0.383975
Epoch (10), Batch(1400/2189), loss: 0.712055, imid loss: 0.169634, imid1 loss: 0.159756, cmid0 loss: 0.382665
Epoch (10), Batch(1600/2189), loss: 0.710517, imid loss: 0.168452, imid1 loss: 0.159930, cmid0 loss: 0.382135
Epoch (10), Batch(1800/2189), loss: 0.708838, imid loss: 0.168097, imid1 loss: 0.159502, cmid0 loss: 0.381238
Epoch (10), Batch(2000/2189), loss: 0.702224, imid loss: 0.165451, imid1 loss: 0.158629, cmid0 loss: 0.378144
Train 10, loss: 0.700726
Linear Accuracy : 0.8991085899513777
==> Saving Best Model...
==> Saving...
Start training epoch: (11/100)
Epoch (11), Batch(0/2189), loss: 0.498378, imid loss: 0.111937, imid1 loss: 0.144004, cmid0 loss: 0.242436
Epoch (11), Batch(200/2189), loss: 0.721572, imid loss: 0.183206, imid1 loss: 0.153776, cmid0 loss: 0.384591
Epoch (11), Batch(400/2189), loss: 0.683274, imid loss: 0.172278, imid1 loss: 0.144679, cmid0 loss: 0.366316
Epoch (11), Batch(600/2189), loss: 0.684936, imid loss: 0.167408, imid1 loss: 0.150323, cmid0 loss: 0.367205
Epoch (11), Batch(800/2189), loss: 0.694309, imid loss: 0.167827, imid1 loss: 0.151690, cmid0 loss: 0.374792
Epoch (11), Batch(1000/2189), loss: 0.697954, imid loss: 0.166622, imid1 loss: 0.153333, cmid0 loss: 0.377998
Epoch (11), Batch(1200/2189), loss: 0.690422, imid loss: 0.164868, imid1 loss: 0.151445, cmid0 loss: 0.374109
Epoch (11), Batch(1400/2189), loss: 0.685071, imid loss: 0.163067, imid1 loss: 0.150641, cmid0 loss: 0.371362
Epoch (11), Batch(1600/2189), loss: 0.680627, imid loss: 0.161777, imid1 loss: 0.150675, cmid0 loss: 0.368174
Epoch (11), Batch(1800/2189), loss: 0.680587, imid loss: 0.161831, imid1 loss: 0.150656, cmid0 loss: 0.368099
Epoch (11), Batch(2000/2189), loss: 0.681409, imid loss: 0.162157, imid1 loss: 0.150977, cmid0 loss: 0.368275
Train 11, loss: 0.675463
Linear Accuracy : 0.8926256077795786
Start training epoch: (12/100)
Epoch (12), Batch(0/2189), loss: 0.204128, imid loss: 0.053967, imid1 loss: 0.024287, cmid0 loss: 0.125874
Epoch (12), Batch(200/2189), loss: 0.625460, imid loss: 0.146362, imid1 loss: 0.138571, cmid0 loss: 0.340527
Epoch (12), Batch(400/2189), loss: 0.627022, imid loss: 0.146690, imid1 loss: 0.139821, cmid0 loss: 0.340511
Epoch (12), Batch(600/2189), loss: 0.625166, imid loss: 0.147057, imid1 loss: 0.138641, cmid0 loss: 0.339468
Epoch (12), Batch(800/2189), loss: 0.628538, imid loss: 0.147270, imid1 loss: 0.138047, cmid0 loss: 0.343221
Epoch (12), Batch(1000/2189), loss: 0.621763, imid loss: 0.146888, imid1 loss: 0.135537, cmid0 loss: 0.339338
Epoch (12), Batch(1200/2189), loss: 0.617919, imid loss: 0.145535, imid1 loss: 0.133912, cmid0 loss: 0.338472
Epoch (12), Batch(1400/2189), loss: 0.621993, imid loss: 0.145964, imid1 loss: 0.136170, cmid0 loss: 0.339858
Epoch (12), Batch(1600/2189), loss: 0.624677, imid loss: 0.146384, imid1 loss: 0.137105, cmid0 loss: 0.341188
Epoch (12), Batch(1800/2189), loss: 0.625087, imid loss: 0.146639, imid1 loss: 0.137168, cmid0 loss: 0.341281
Epoch (12), Batch(2000/2189), loss: 0.623588, imid loss: 0.146264, imid1 loss: 0.137195, cmid0 loss: 0.340129
Train 12, loss: 0.620281
Linear Accuracy : 0.8885737439222042
Start training epoch: (13/100)
Epoch (13), Batch(0/2189), loss: 1.166812, imid loss: 0.407303, imid1 loss: 0.126885, cmid0 loss: 0.632624
Epoch (13), Batch(200/2189), loss: 0.632562, imid loss: 0.161691, imid1 loss: 0.135520, cmid0 loss: 0.335350
Epoch (13), Batch(400/2189), loss: 0.613391, imid loss: 0.146740, imid1 loss: 0.138754, cmid0 loss: 0.327898
Epoch (13), Batch(600/2189), loss: 0.606216, imid loss: 0.146151, imid1 loss: 0.136502, cmid0 loss: 0.323563
Epoch (13), Batch(800/2189), loss: 0.602520, imid loss: 0.144988, imid1 loss: 0.134439, cmid0 loss: 0.323093
Epoch (13), Batch(1000/2189), loss: 0.595171, imid loss: 0.141485, imid1 loss: 0.132970, cmid0 loss: 0.320716
Epoch (13), Batch(1200/2189), loss: 0.602527, imid loss: 0.141924, imid1 loss: 0.134057, cmid0 loss: 0.326546
Epoch (13), Batch(1400/2189), loss: 0.605290, imid loss: 0.142462, imid1 loss: 0.135141, cmid0 loss: 0.327687
Epoch (13), Batch(1600/2189), loss: 0.609724, imid loss: 0.143905, imid1 loss: 0.135571, cmid0 loss: 0.330249
Epoch (13), Batch(1800/2189), loss: 0.607679, imid loss: 0.143537, imid1 loss: 0.134408, cmid0 loss: 0.329733
Epoch (13), Batch(2000/2189), loss: 0.604135, imid loss: 0.142641, imid1 loss: 0.133497, cmid0 loss: 0.327997
Train 13, loss: 0.602848
Linear Accuracy : 0.8934359805510534
Start training epoch: (14/100)
Epoch (14), Batch(0/2189), loss: 0.190704, imid loss: 0.058448, imid1 loss: 0.057772, cmid0 loss: 0.074483
Epoch (14), Batch(200/2189), loss: 0.545037, imid loss: 0.133898, imid1 loss: 0.121879, cmid0 loss: 0.289260
Epoch (14), Batch(400/2189), loss: 0.553154, imid loss: 0.131070, imid1 loss: 0.126414, cmid0 loss: 0.295669
Epoch (14), Batch(600/2189), loss: 0.568646, imid loss: 0.132631, imid1 loss: 0.130454, cmid0 loss: 0.305561
Epoch (14), Batch(800/2189), loss: 0.568017, imid loss: 0.134602, imid1 loss: 0.128303, cmid0 loss: 0.305112
Epoch (14), Batch(1000/2189), loss: 0.580140, imid loss: 0.137275, imid1 loss: 0.129716, cmid0 loss: 0.313149
Epoch (14), Batch(1200/2189), loss: 0.579680, imid loss: 0.137539, imid1 loss: 0.129277, cmid0 loss: 0.312864
Epoch (14), Batch(1400/2189), loss: 0.580254, imid loss: 0.137405, imid1 loss: 0.129443, cmid0 loss: 0.313406
Epoch (14), Batch(1600/2189), loss: 0.576338, imid loss: 0.136683, imid1 loss: 0.128793, cmid0 loss: 0.310863
Epoch (14), Batch(1800/2189), loss: 0.574124, imid loss: 0.135921, imid1 loss: 0.127565, cmid0 loss: 0.310638
Epoch (14), Batch(2000/2189), loss: 0.571606, imid loss: 0.135521, imid1 loss: 0.126869, cmid0 loss: 0.309216
Train 14, loss: 0.572861
Linear Accuracy : 0.8893841166936791
Start training epoch: (15/100)
Epoch (15), Batch(0/2189), loss: 0.880113, imid loss: 0.251740, imid1 loss: 0.324964, cmid0 loss: 0.303408
Epoch (15), Batch(200/2189), loss: 0.592281, imid loss: 0.140388, imid1 loss: 0.139444, cmid0 loss: 0.312449
Epoch (15), Batch(400/2189), loss: 0.570787, imid loss: 0.134790, imid1 loss: 0.136698, cmid0 loss: 0.299299
Epoch (15), Batch(600/2189), loss: 0.559874, imid loss: 0.131872, imid1 loss: 0.132090, cmid0 loss: 0.295912
Epoch (15), Batch(800/2189), loss: 0.560069, imid loss: 0.133663, imid1 loss: 0.128550, cmid0 loss: 0.297856
Epoch (15), Batch(1000/2189), loss: 0.553427, imid loss: 0.131830, imid1 loss: 0.124681, cmid0 loss: 0.296916
Epoch (15), Batch(1200/2189), loss: 0.547058, imid loss: 0.129744, imid1 loss: 0.123414, cmid0 loss: 0.293901
Epoch (15), Batch(1400/2189), loss: 0.547193, imid loss: 0.130173, imid1 loss: 0.122973, cmid0 loss: 0.294046
Epoch (15), Batch(1600/2189), loss: 0.551723, imid loss: 0.132712, imid1 loss: 0.123718, cmid0 loss: 0.295293
Epoch (15), Batch(1800/2189), loss: 0.553195, imid loss: 0.133632, imid1 loss: 0.123733, cmid0 loss: 0.295830
Epoch (15), Batch(2000/2189), loss: 0.554780, imid loss: 0.133896, imid1 loss: 0.123493, cmid0 loss: 0.297391
Train 15, loss: 0.553319
Linear Accuracy : 0.8926256077795786
==> Saving...
Start training epoch: (16/100)
Epoch (16), Batch(0/2189), loss: 0.286669, imid loss: 0.032053, imid1 loss: 0.158977, cmid0 loss: 0.095639
Epoch (16), Batch(200/2189), loss: 0.529042, imid loss: 0.129342, imid1 loss: 0.116122, cmid0 loss: 0.283579
Epoch (16), Batch(400/2189), loss: 0.526305, imid loss: 0.127436, imid1 loss: 0.114184, cmid0 loss: 0.284685
Epoch (16), Batch(600/2189), loss: 0.528830, imid loss: 0.129095, imid1 loss: 0.114523, cmid0 loss: 0.285212
Epoch (16), Batch(800/2189), loss: 0.520859, imid loss: 0.124800, imid1 loss: 0.112968, cmid0 loss: 0.283092
Epoch (16), Batch(1000/2189), loss: 0.519452, imid loss: 0.123184, imid1 loss: 0.113467, cmid0 loss: 0.282800
Epoch (16), Batch(1200/2189), loss: 0.520501, imid loss: 0.123272, imid1 loss: 0.115389, cmid0 loss: 0.281840
Epoch (16), Batch(1400/2189), loss: 0.520059, imid loss: 0.123370, imid1 loss: 0.114407, cmid0 loss: 0.282282
Epoch (16), Batch(1600/2189), loss: 0.516201, imid loss: 0.122528, imid1 loss: 0.112350, cmid0 loss: 0.281323
Epoch (16), Batch(1800/2189), loss: 0.518011, imid loss: 0.122730, imid1 loss: 0.112434, cmid0 loss: 0.282847
Epoch (16), Batch(2000/2189), loss: 0.517931, imid loss: 0.122454, imid1 loss: 0.112712, cmid0 loss: 0.282766
Train 16, loss: 0.518722
Linear Accuracy : 0.8991085899513777
Start training epoch: (17/100)
Epoch (17), Batch(0/2189), loss: 0.955620, imid loss: 0.078543, imid1 loss: 0.443803, cmid0 loss: 0.433273
Epoch (17), Batch(200/2189), loss: 0.484333, imid loss: 0.118029, imid1 loss: 0.108886, cmid0 loss: 0.257418
Epoch (17), Batch(400/2189), loss: 0.499944, imid loss: 0.120090, imid1 loss: 0.113516, cmid0 loss: 0.266338
Epoch (17), Batch(600/2189), loss: 0.501425, imid loss: 0.118945, imid1 loss: 0.111811, cmid0 loss: 0.270668
Epoch (17), Batch(800/2189), loss: 0.506766, imid loss: 0.121409, imid1 loss: 0.112461, cmid0 loss: 0.272895
Epoch (17), Batch(1000/2189), loss: 0.507337, imid loss: 0.121247, imid1 loss: 0.111805, cmid0 loss: 0.274285
Epoch (17), Batch(1200/2189), loss: 0.504823, imid loss: 0.120320, imid1 loss: 0.112030, cmid0 loss: 0.272473
Epoch (17), Batch(1400/2189), loss: 0.503663, imid loss: 0.119528, imid1 loss: 0.111969, cmid0 loss: 0.272166
Epoch (17), Batch(1600/2189), loss: 0.502188, imid loss: 0.119355, imid1 loss: 0.111858, cmid0 loss: 0.270975
Epoch (17), Batch(1800/2189), loss: 0.502373, imid loss: 0.119254, imid1 loss: 0.112920, cmid0 loss: 0.270200
Epoch (17), Batch(2000/2189), loss: 0.502075, imid loss: 0.120377, imid1 loss: 0.112588, cmid0 loss: 0.269110
Train 17, loss: 0.502320
Linear Accuracy : 0.8914100486223663
Start training epoch: (18/100)
Epoch (18), Batch(0/2189), loss: 0.438022, imid loss: 0.128424, imid1 loss: 0.051576, cmid0 loss: 0.258022
Epoch (18), Batch(200/2189), loss: 0.467998, imid loss: 0.106733, imid1 loss: 0.103896, cmid0 loss: 0.257369
Epoch (18), Batch(400/2189), loss: 0.477733, imid loss: 0.110131, imid1 loss: 0.108461, cmid0 loss: 0.259141
Epoch (18), Batch(600/2189), loss: 0.477876, imid loss: 0.111996, imid1 loss: 0.106703, cmid0 loss: 0.259177
Epoch (18), Batch(800/2189), loss: 0.482787, imid loss: 0.113713, imid1 loss: 0.107697, cmid0 loss: 0.261378
Epoch (18), Batch(1000/2189), loss: 0.477443, imid loss: 0.111860, imid1 loss: 0.106807, cmid0 loss: 0.258776
Epoch (18), Batch(1200/2189), loss: 0.479461, imid loss: 0.113406, imid1 loss: 0.106507, cmid0 loss: 0.259548
Epoch (18), Batch(1400/2189), loss: 0.479502, imid loss: 0.113756, imid1 loss: 0.106714, cmid0 loss: 0.259033
Epoch (18), Batch(1600/2189), loss: 0.476410, imid loss: 0.113955, imid1 loss: 0.105461, cmid0 loss: 0.256994
Epoch (18), Batch(1800/2189), loss: 0.476175, imid loss: 0.113286, imid1 loss: 0.106259, cmid0 loss: 0.256630
Epoch (18), Batch(2000/2189), loss: 0.477664, imid loss: 0.113376, imid1 loss: 0.106667, cmid0 loss: 0.257621
Train 18, loss: 0.477210
Linear Accuracy : 0.8889789303079416
Start training epoch: (19/100)
Epoch (19), Batch(0/2189), loss: 0.337757, imid loss: 0.041706, imid1 loss: 0.091842, cmid0 loss: 0.204209
Epoch (19), Batch(200/2189), loss: 0.457339, imid loss: 0.107840, imid1 loss: 0.097798, cmid0 loss: 0.251701
Epoch (19), Batch(400/2189), loss: 0.449725, imid loss: 0.106737, imid1 loss: 0.094270, cmid0 loss: 0.248718
Epoch (19), Batch(600/2189), loss: 0.442524, imid loss: 0.103569, imid1 loss: 0.095396, cmid0 loss: 0.243560
Epoch (19), Batch(800/2189), loss: 0.447979, imid loss: 0.104612, imid1 loss: 0.098246, cmid0 loss: 0.245121
Epoch (19), Batch(1000/2189), loss: 0.457429, imid loss: 0.108253, imid1 loss: 0.099861, cmid0 loss: 0.249315
Epoch (19), Batch(1200/2189), loss: 0.454458, imid loss: 0.107394, imid1 loss: 0.099968, cmid0 loss: 0.247096
Epoch (19), Batch(1400/2189), loss: 0.451060, imid loss: 0.107563, imid1 loss: 0.099184, cmid0 loss: 0.244312
Epoch (19), Batch(1600/2189), loss: 0.454307, imid loss: 0.108016, imid1 loss: 0.100560, cmid0 loss: 0.245731
Epoch (19), Batch(1800/2189), loss: 0.452104, imid loss: 0.107014, imid1 loss: 0.100767, cmid0 loss: 0.244323
Epoch (19), Batch(2000/2189), loss: 0.451721, imid loss: 0.106612, imid1 loss: 0.101496, cmid0 loss: 0.243613
Train 19, loss: 0.452658
Linear Accuracy : 0.8914100486223663
Start training epoch: (20/100)
Epoch (20), Batch(0/2189), loss: 0.571457, imid loss: 0.102961, imid1 loss: 0.263959, cmid0 loss: 0.204537
Epoch (20), Batch(200/2189), loss: 0.463180, imid loss: 0.120113, imid1 loss: 0.106254, cmid0 loss: 0.236813
Epoch (20), Batch(400/2189), loss: 0.451991, imid loss: 0.112480, imid1 loss: 0.101185, cmid0 loss: 0.238326
Epoch (20), Batch(600/2189), loss: 0.457374, imid loss: 0.111986, imid1 loss: 0.103015, cmid0 loss: 0.242373
Epoch (20), Batch(800/2189), loss: 0.456064, imid loss: 0.111927, imid1 loss: 0.101052, cmid0 loss: 0.243084
Epoch (20), Batch(1000/2189), loss: 0.453100, imid loss: 0.110698, imid1 loss: 0.100954, cmid0 loss: 0.241448
Epoch (20), Batch(1200/2189), loss: 0.455428, imid loss: 0.110956, imid1 loss: 0.101706, cmid0 loss: 0.242765
Epoch (20), Batch(1400/2189), loss: 0.450210, imid loss: 0.108449, imid1 loss: 0.101029, cmid0 loss: 0.240732
Epoch (20), Batch(1600/2189), loss: 0.448411, imid loss: 0.107780, imid1 loss: 0.101058, cmid0 loss: 0.239573
Epoch (20), Batch(1800/2189), loss: 0.448045, imid loss: 0.108326, imid1 loss: 0.100963, cmid0 loss: 0.238756
Epoch (20), Batch(2000/2189), loss: 0.454245, imid loss: 0.109698, imid1 loss: 0.102835, cmid0 loss: 0.241711
Train 20, loss: 0.453784
Linear Accuracy : 0.8869529983792545
==> Saving...
Start training epoch: (21/100)
Epoch (21), Batch(0/2189), loss: 0.491365, imid loss: 0.109929, imid1 loss: 0.175584, cmid0 loss: 0.205853
Epoch (21), Batch(200/2189), loss: 0.450257, imid loss: 0.114998, imid1 loss: 0.096139, cmid0 loss: 0.239121
Epoch (21), Batch(400/2189), loss: 0.456005, imid loss: 0.109870, imid1 loss: 0.101481, cmid0 loss: 0.244653
Epoch (21), Batch(600/2189), loss: 0.457150, imid loss: 0.110144, imid1 loss: 0.099664, cmid0 loss: 0.247342
Epoch (21), Batch(800/2189), loss: 0.449570, imid loss: 0.108464, imid1 loss: 0.097453, cmid0 loss: 0.243653
Epoch (21), Batch(1000/2189), loss: 0.448221, imid loss: 0.108367, imid1 loss: 0.097872, cmid0 loss: 0.241982
Epoch (21), Batch(1200/2189), loss: 0.445842, imid loss: 0.107937, imid1 loss: 0.096768, cmid0 loss: 0.241137
Epoch (21), Batch(1400/2189), loss: 0.443317, imid loss: 0.106940, imid1 loss: 0.095398, cmid0 loss: 0.240980
Epoch (21), Batch(1600/2189), loss: 0.443514, imid loss: 0.107938, imid1 loss: 0.095104, cmid0 loss: 0.240472
Epoch (21), Batch(1800/2189), loss: 0.444120, imid loss: 0.107571, imid1 loss: 0.096011, cmid0 loss: 0.240539
Epoch (21), Batch(2000/2189), loss: 0.440261, imid loss: 0.106953, imid1 loss: 0.095225, cmid0 loss: 0.238083
Train 21, loss: 0.441355
Linear Accuracy : 0.8934359805510534
Start training epoch: (22/100)
Epoch (22), Batch(0/2189), loss: 0.824890, imid loss: 0.138205, imid1 loss: 0.292171, cmid0 loss: 0.394514
Epoch (22), Batch(200/2189), loss: 0.421593, imid loss: 0.098537, imid1 loss: 0.102610, cmid0 loss: 0.220446
Epoch (22), Batch(400/2189), loss: 0.418053, imid loss: 0.097222, imid1 loss: 0.099281, cmid0 loss: 0.221550
Epoch (22), Batch(600/2189), loss: 0.416543, imid loss: 0.097417, imid1 loss: 0.094826, cmid0 loss: 0.224299
Epoch (22), Batch(800/2189), loss: 0.419053, imid loss: 0.099261, imid1 loss: 0.093946, cmid0 loss: 0.225847
Epoch (22), Batch(1000/2189), loss: 0.424653, imid loss: 0.100617, imid1 loss: 0.093437, cmid0 loss: 0.230600
Epoch (22), Batch(1200/2189), loss: 0.424475, imid loss: 0.101128, imid1 loss: 0.094015, cmid0 loss: 0.229332
Epoch (22), Batch(1400/2189), loss: 0.426893, imid loss: 0.102124, imid1 loss: 0.095101, cmid0 loss: 0.229668
Epoch (22), Batch(1600/2189), loss: 0.427006, imid loss: 0.101934, imid1 loss: 0.096636, cmid0 loss: 0.228436
Epoch (22), Batch(1800/2189), loss: 0.427429, imid loss: 0.101458, imid1 loss: 0.097412, cmid0 loss: 0.228559
Epoch (22), Batch(2000/2189), loss: 0.427606, imid loss: 0.101611, imid1 loss: 0.097491, cmid0 loss: 0.228504
Train 22, loss: 0.429623
Linear Accuracy : 0.8946515397082658
Start training epoch: (23/100)
Epoch (23), Batch(0/2189), loss: 0.570930, imid loss: 0.133803, imid1 loss: 0.158925, cmid0 loss: 0.278202
Epoch (23), Batch(200/2189), loss: 0.383164, imid loss: 0.096186, imid1 loss: 0.081609, cmid0 loss: 0.205369
Epoch (23), Batch(400/2189), loss: 0.393101, imid loss: 0.096252, imid1 loss: 0.086546, cmid0 loss: 0.210304
Epoch (23), Batch(600/2189), loss: 0.395421, imid loss: 0.097236, imid1 loss: 0.087073, cmid0 loss: 0.211113
Epoch (23), Batch(800/2189), loss: 0.400002, imid loss: 0.098803, imid1 loss: 0.087595, cmid0 loss: 0.213604
Epoch (23), Batch(1000/2189), loss: 0.407004, imid loss: 0.100732, imid1 loss: 0.088887, cmid0 loss: 0.217384
Epoch (23), Batch(1200/2189), loss: 0.409634, imid loss: 0.101440, imid1 loss: 0.089607, cmid0 loss: 0.218588
Epoch (23), Batch(1400/2189), loss: 0.406489, imid loss: 0.100681, imid1 loss: 0.089089, cmid0 loss: 0.216719
Epoch (23), Batch(1600/2189), loss: 0.407213, imid loss: 0.100105, imid1 loss: 0.088909, cmid0 loss: 0.218199
Epoch (23), Batch(1800/2189), loss: 0.406278, imid loss: 0.099582, imid1 loss: 0.089104, cmid0 loss: 0.217593
Epoch (23), Batch(2000/2189), loss: 0.407110, imid loss: 0.099399, imid1 loss: 0.089803, cmid0 loss: 0.217908
Train 23, loss: 0.405963
Linear Accuracy : 0.8853322528363047
Start training epoch: (24/100)
Epoch (24), Batch(0/2189), loss: 0.569627, imid loss: 0.132111, imid1 loss: 0.057641, cmid0 loss: 0.379875
Epoch (24), Batch(200/2189), loss: 0.416905, imid loss: 0.095394, imid1 loss: 0.095756, cmid0 loss: 0.225755
Epoch (24), Batch(400/2189), loss: 0.399778, imid loss: 0.093254, imid1 loss: 0.090688, cmid0 loss: 0.215835
Epoch (24), Batch(600/2189), loss: 0.390848, imid loss: 0.092966, imid1 loss: 0.087270, cmid0 loss: 0.210612
Epoch (24), Batch(800/2189), loss: 0.387131, imid loss: 0.091971, imid1 loss: 0.087088, cmid0 loss: 0.208072
Epoch (24), Batch(1000/2189), loss: 0.387944, imid loss: 0.092182, imid1 loss: 0.088132, cmid0 loss: 0.207629
Epoch (24), Batch(1200/2189), loss: 0.396993, imid loss: 0.094361, imid1 loss: 0.089533, cmid0 loss: 0.213100
Epoch (24), Batch(1400/2189), loss: 0.394699, imid loss: 0.094685, imid1 loss: 0.088273, cmid0 loss: 0.211740
Epoch (24), Batch(1600/2189), loss: 0.397438, imid loss: 0.095816, imid1 loss: 0.088371, cmid0 loss: 0.213250
Epoch (24), Batch(1800/2189), loss: 0.394868, imid loss: 0.095288, imid1 loss: 0.088066, cmid0 loss: 0.211514
Epoch (24), Batch(2000/2189), loss: 0.393170, imid loss: 0.094588, imid1 loss: 0.087440, cmid0 loss: 0.211143
Train 24, loss: 0.396461
Linear Accuracy : 0.8962722852512156
Start training epoch: (25/100)
Epoch (25), Batch(0/2189), loss: 0.597732, imid loss: 0.145580, imid1 loss: 0.168690, cmid0 loss: 0.283461
Epoch (25), Batch(200/2189), loss: 0.395551, imid loss: 0.095081, imid1 loss: 0.093320, cmid0 loss: 0.207150
Epoch (25), Batch(400/2189), loss: 0.395973, imid loss: 0.096998, imid1 loss: 0.090073, cmid0 loss: 0.208901
Epoch (25), Batch(600/2189), loss: 0.385519, imid loss: 0.091641, imid1 loss: 0.087698, cmid0 loss: 0.206180
Epoch (25), Batch(800/2189), loss: 0.375865, imid loss: 0.089505, imid1 loss: 0.084873, cmid0 loss: 0.201487
Epoch (25), Batch(1000/2189), loss: 0.375291, imid loss: 0.089497, imid1 loss: 0.084375, cmid0 loss: 0.201419
Epoch (25), Batch(1200/2189), loss: 0.376912, imid loss: 0.090818, imid1 loss: 0.083982, cmid0 loss: 0.202112
Epoch (25), Batch(1400/2189), loss: 0.381188, imid loss: 0.091807, imid1 loss: 0.084731, cmid0 loss: 0.204650
Epoch (25), Batch(1600/2189), loss: 0.381664, imid loss: 0.092848, imid1 loss: 0.084704, cmid0 loss: 0.204113
Epoch (25), Batch(1800/2189), loss: 0.384400, imid loss: 0.093351, imid1 loss: 0.085975, cmid0 loss: 0.205074
Epoch (25), Batch(2000/2189), loss: 0.384849, imid loss: 0.093274, imid1 loss: 0.086032, cmid0 loss: 0.205543
Train 25, loss: 0.385754
Linear Accuracy : 0.8918152350081038
==> Saving...
Start training epoch: (26/100)
Epoch (26), Batch(0/2189), loss: 0.866063, imid loss: 0.359637, imid1 loss: 0.074463, cmid0 loss: 0.431962
Epoch (26), Batch(200/2189), loss: 0.366956, imid loss: 0.086677, imid1 loss: 0.080209, cmid0 loss: 0.200070
Epoch (26), Batch(400/2189), loss: 0.383795, imid loss: 0.091494, imid1 loss: 0.086379, cmid0 loss: 0.205922
Epoch (26), Batch(600/2189), loss: 0.384949, imid loss: 0.091094, imid1 loss: 0.088380, cmid0 loss: 0.205475
Epoch (26), Batch(800/2189), loss: 0.377895, imid loss: 0.088839, imid1 loss: 0.088245, cmid0 loss: 0.200811
Epoch (26), Batch(1000/2189), loss: 0.380444, imid loss: 0.089039, imid1 loss: 0.088002, cmid0 loss: 0.203404
Epoch (26), Batch(1200/2189), loss: 0.377282, imid loss: 0.089119, imid1 loss: 0.086499, cmid0 loss: 0.201664
Epoch (26), Batch(1400/2189), loss: 0.377702, imid loss: 0.089834, imid1 loss: 0.085834, cmid0 loss: 0.202034
Epoch (26), Batch(1600/2189), loss: 0.374618, imid loss: 0.089125, imid1 loss: 0.084788, cmid0 loss: 0.200705
Epoch (26), Batch(1800/2189), loss: 0.373467, imid loss: 0.089737, imid1 loss: 0.084116, cmid0 loss: 0.199614
Epoch (26), Batch(2000/2189), loss: 0.373808, imid loss: 0.089484, imid1 loss: 0.084615, cmid0 loss: 0.199708
Train 26, loss: 0.374267
Linear Accuracy : 0.899513776337115
==> Saving Best Model...
Start training epoch: (27/100)
Epoch (27), Batch(0/2189), loss: 0.255189, imid loss: 0.072767, imid1 loss: 0.010289, cmid0 loss: 0.172134
Epoch (27), Batch(200/2189), loss: 0.386686, imid loss: 0.093900, imid1 loss: 0.087631, cmid0 loss: 0.205155
Epoch (27), Batch(400/2189), loss: 0.373127, imid loss: 0.089322, imid1 loss: 0.086009, cmid0 loss: 0.197797
Epoch (27), Batch(600/2189), loss: 0.364264, imid loss: 0.086255, imid1 loss: 0.082998, cmid0 loss: 0.195011
Epoch (27), Batch(800/2189), loss: 0.369968, imid loss: 0.088942, imid1 loss: 0.084266, cmid0 loss: 0.196760
Epoch (27), Batch(1000/2189), loss: 0.369338, imid loss: 0.089613, imid1 loss: 0.082805, cmid0 loss: 0.196920
Epoch (27), Batch(1200/2189), loss: 0.372148, imid loss: 0.090223, imid1 loss: 0.083332, cmid0 loss: 0.198593
Epoch (27), Batch(1400/2189), loss: 0.373690, imid loss: 0.091034, imid1 loss: 0.083066, cmid0 loss: 0.199590
Epoch (27), Batch(1600/2189), loss: 0.371589, imid loss: 0.091175, imid1 loss: 0.081942, cmid0 loss: 0.198471
Epoch (27), Batch(1800/2189), loss: 0.371314, imid loss: 0.091216, imid1 loss: 0.081513, cmid0 loss: 0.198586
Epoch (27), Batch(2000/2189), loss: 0.369906, imid loss: 0.091253, imid1 loss: 0.080902, cmid0 loss: 0.197751
Train 27, loss: 0.367295
Linear Accuracy : 0.896677471636953
Start training epoch: (28/100)
Epoch (28), Batch(0/2189), loss: 0.239339, imid loss: 0.031851, imid1 loss: 0.018816, cmid0 loss: 0.188672
Epoch (28), Batch(200/2189), loss: 0.357726, imid loss: 0.093716, imid1 loss: 0.076264, cmid0 loss: 0.187746
Epoch (28), Batch(400/2189), loss: 0.366542, imid loss: 0.092396, imid1 loss: 0.076370, cmid0 loss: 0.197776
Epoch (28), Batch(600/2189), loss: 0.360662, imid loss: 0.089002, imid1 loss: 0.078812, cmid0 loss: 0.192848
Epoch (28), Batch(800/2189), loss: 0.365244, imid loss: 0.090211, imid1 loss: 0.081088, cmid0 loss: 0.193946
Epoch (28), Batch(1000/2189), loss: 0.363455, imid loss: 0.089601, imid1 loss: 0.081092, cmid0 loss: 0.192762
Epoch (28), Batch(1200/2189), loss: 0.363360, imid loss: 0.089146, imid1 loss: 0.081442, cmid0 loss: 0.192772
Epoch (28), Batch(1400/2189), loss: 0.364495, imid loss: 0.088655, imid1 loss: 0.082087, cmid0 loss: 0.193753
Epoch (28), Batch(1600/2189), loss: 0.361627, imid loss: 0.087686, imid1 loss: 0.082023, cmid0 loss: 0.191918
Epoch (28), Batch(1800/2189), loss: 0.364771, imid loss: 0.089083, imid1 loss: 0.082003, cmid0 loss: 0.193684
Epoch (28), Batch(2000/2189), loss: 0.362062, imid loss: 0.088196, imid1 loss: 0.081263, cmid0 loss: 0.192603
Train 28, loss: 0.361835
Linear Accuracy : 0.9055915721231766
==> Saving Best Model...
Start training epoch: (29/100)
Epoch (29), Batch(0/2189), loss: 0.146521, imid loss: 0.026597, imid1 loss: 0.040392, cmid0 loss: 0.079532
Epoch (29), Batch(200/2189), loss: 0.350537, imid loss: 0.087162, imid1 loss: 0.082295, cmid0 loss: 0.181081
Epoch (29), Batch(400/2189), loss: 0.354002, imid loss: 0.084930, imid1 loss: 0.081093, cmid0 loss: 0.187978
Epoch (29), Batch(600/2189), loss: 0.353026, imid loss: 0.085147, imid1 loss: 0.082638, cmid0 loss: 0.185241
Epoch (29), Batch(800/2189), loss: 0.351174, imid loss: 0.085799, imid1 loss: 0.080070, cmid0 loss: 0.185305
Epoch (29), Batch(1000/2189), loss: 0.349645, imid loss: 0.085399, imid1 loss: 0.078909, cmid0 loss: 0.185337
Epoch (29), Batch(1200/2189), loss: 0.347044, imid loss: 0.085087, imid1 loss: 0.077295, cmid0 loss: 0.184663
Epoch (29), Batch(1400/2189), loss: 0.343930, imid loss: 0.084024, imid1 loss: 0.076865, cmid0 loss: 0.183041
Epoch (29), Batch(1600/2189), loss: 0.345561, imid loss: 0.084434, imid1 loss: 0.077435, cmid0 loss: 0.183691
Epoch (29), Batch(1800/2189), loss: 0.346647, imid loss: 0.084653, imid1 loss: 0.078235, cmid0 loss: 0.183760
Epoch (29), Batch(2000/2189), loss: 0.347835, imid loss: 0.084915, imid1 loss: 0.078304, cmid0 loss: 0.184616
Train 29, loss: 0.348181
Linear Accuracy : 0.8978930307941653
Start training epoch: (30/100)
Epoch (30), Batch(0/2189), loss: 0.165764, imid loss: 0.051116, imid1 loss: 0.024983, cmid0 loss: 0.089664
Epoch (30), Batch(200/2189), loss: 0.325209, imid loss: 0.076837, imid1 loss: 0.080223, cmid0 loss: 0.168149
Epoch (30), Batch(400/2189), loss: 0.334185, imid loss: 0.079583, imid1 loss: 0.078100, cmid0 loss: 0.176502
Epoch (30), Batch(600/2189), loss: 0.339895, imid loss: 0.080894, imid1 loss: 0.076190, cmid0 loss: 0.182811
Epoch (30), Batch(800/2189), loss: 0.339499, imid loss: 0.081633, imid1 loss: 0.077034, cmid0 loss: 0.180832
Epoch (30), Batch(1000/2189), loss: 0.338123, imid loss: 0.081976, imid1 loss: 0.076138, cmid0 loss: 0.180008
Epoch (30), Batch(1200/2189), loss: 0.341398, imid loss: 0.082665, imid1 loss: 0.076512, cmid0 loss: 0.182220
Epoch (30), Batch(1400/2189), loss: 0.338922, imid loss: 0.081797, imid1 loss: 0.076232, cmid0 loss: 0.180894
Epoch (30), Batch(1600/2189), loss: 0.339441, imid loss: 0.082243, imid1 loss: 0.075513, cmid0 loss: 0.181685
Epoch (30), Batch(1800/2189), loss: 0.340959, imid loss: 0.083132, imid1 loss: 0.075416, cmid0 loss: 0.182411
Epoch (30), Batch(2000/2189), loss: 0.339560, imid loss: 0.082963, imid1 loss: 0.074619, cmid0 loss: 0.181978
Train 30, loss: 0.338690
Linear Accuracy : 0.899513776337115
==> Saving...
Start training epoch: (31/100)
Epoch (31), Batch(0/2189), loss: 0.338634, imid loss: 0.092288, imid1 loss: 0.035388, cmid0 loss: 0.210958
Epoch (31), Batch(200/2189), loss: 0.312740, imid loss: 0.074249, imid1 loss: 0.065399, cmid0 loss: 0.173092
Epoch (31), Batch(400/2189), loss: 0.312193, imid loss: 0.074402, imid1 loss: 0.066397, cmid0 loss: 0.171394
Epoch (31), Batch(600/2189), loss: 0.325798, imid loss: 0.079527, imid1 loss: 0.067959, cmid0 loss: 0.178312
Epoch (31), Batch(800/2189), loss: 0.331054, imid loss: 0.080468, imid1 loss: 0.071498, cmid0 loss: 0.179089
Epoch (31), Batch(1000/2189), loss: 0.329923, imid loss: 0.080629, imid1 loss: 0.069954, cmid0 loss: 0.179339
Epoch (31), Batch(1200/2189), loss: 0.334432, imid loss: 0.081902, imid1 loss: 0.071469, cmid0 loss: 0.181061
Epoch (31), Batch(1400/2189), loss: 0.332622, imid loss: 0.081456, imid1 loss: 0.071697, cmid0 loss: 0.179468
Epoch (31), Batch(1600/2189), loss: 0.333534, imid loss: 0.081889, imid1 loss: 0.072049, cmid0 loss: 0.179595
Epoch (31), Batch(1800/2189), loss: 0.331936, imid loss: 0.081326, imid1 loss: 0.071436, cmid0 loss: 0.179174
Epoch (31), Batch(2000/2189), loss: 0.330855, imid loss: 0.080470, imid1 loss: 0.071685, cmid0 loss: 0.178700
Train 31, loss: 0.332795
Linear Accuracy : 0.8974878444084279
Start training epoch: (32/100)
Epoch (32), Batch(0/2189), loss: 0.099808, imid loss: 0.025417, imid1 loss: 0.015617, cmid0 loss: 0.058774
Epoch (32), Batch(200/2189), loss: 0.335989, imid loss: 0.085558, imid1 loss: 0.076106, cmid0 loss: 0.174324
Epoch (32), Batch(400/2189), loss: 0.325444, imid loss: 0.079399, imid1 loss: 0.074939, cmid0 loss: 0.171106
Epoch (32), Batch(600/2189), loss: 0.323479, imid loss: 0.076885, imid1 loss: 0.075454, cmid0 loss: 0.171139
Epoch (32), Batch(800/2189), loss: 0.323016, imid loss: 0.078246, imid1 loss: 0.074584, cmid0 loss: 0.170186
Epoch (32), Batch(1000/2189), loss: 0.318900, imid loss: 0.076710, imid1 loss: 0.073471, cmid0 loss: 0.168719
Epoch (32), Batch(1200/2189), loss: 0.315901, imid loss: 0.076691, imid1 loss: 0.071864, cmid0 loss: 0.167345
Epoch (32), Batch(1400/2189), loss: 0.317829, imid loss: 0.077690, imid1 loss: 0.071639, cmid0 loss: 0.168501
Epoch (32), Batch(1600/2189), loss: 0.321990, imid loss: 0.078687, imid1 loss: 0.072651, cmid0 loss: 0.170652
Epoch (32), Batch(1800/2189), loss: 0.320768, imid loss: 0.078363, imid1 loss: 0.071632, cmid0 loss: 0.170773
Epoch (32), Batch(2000/2189), loss: 0.320329, imid loss: 0.078424, imid1 loss: 0.071784, cmid0 loss: 0.170122
Train 32, loss: 0.322913
Linear Accuracy : 0.8914100486223663
Start training epoch: (33/100)
Epoch (33), Batch(0/2189), loss: 0.298679, imid loss: 0.041096, imid1 loss: 0.044002, cmid0 loss: 0.213582
Epoch (33), Batch(200/2189), loss: 0.313352, imid loss: 0.078004, imid1 loss: 0.075881, cmid0 loss: 0.159468
Epoch (33), Batch(400/2189), loss: 0.330097, imid loss: 0.082796, imid1 loss: 0.078095, cmid0 loss: 0.169206
Epoch (33), Batch(600/2189), loss: 0.320172, imid loss: 0.077641, imid1 loss: 0.077380, cmid0 loss: 0.165150
Epoch (33), Batch(800/2189), loss: 0.316414, imid loss: 0.076886, imid1 loss: 0.074141, cmid0 loss: 0.165387
Epoch (33), Batch(1000/2189), loss: 0.317863, imid loss: 0.077592, imid1 loss: 0.072607, cmid0 loss: 0.167665
Epoch (33), Batch(1200/2189), loss: 0.314976, imid loss: 0.077803, imid1 loss: 0.070961, cmid0 loss: 0.166212
Epoch (33), Batch(1400/2189), loss: 0.315343, imid loss: 0.077092, imid1 loss: 0.071461, cmid0 loss: 0.166791
Epoch (33), Batch(1600/2189), loss: 0.314830, imid loss: 0.077477, imid1 loss: 0.070546, cmid0 loss: 0.166808
Epoch (33), Batch(1800/2189), loss: 0.313207, imid loss: 0.077043, imid1 loss: 0.070196, cmid0 loss: 0.165969
Epoch (33), Batch(2000/2189), loss: 0.311519, imid loss: 0.076198, imid1 loss: 0.070083, cmid0 loss: 0.165238
Train 33, loss: 0.311313
Linear Accuracy : 0.8934359805510534
Start training epoch: (34/100)
Epoch (34), Batch(0/2189), loss: 0.355499, imid loss: 0.121376, imid1 loss: 0.013953, cmid0 loss: 0.220171
Epoch (34), Batch(200/2189), loss: 0.309449, imid loss: 0.074537, imid1 loss: 0.065381, cmid0 loss: 0.169531
Epoch (34), Batch(400/2189), loss: 0.310635, imid loss: 0.078436, imid1 loss: 0.065894, cmid0 loss: 0.166305
Epoch (34), Batch(600/2189), loss: 0.313732, imid loss: 0.079486, imid1 loss: 0.067240, cmid0 loss: 0.167006
Epoch (34), Batch(800/2189), loss: 0.318685, imid loss: 0.079982, imid1 loss: 0.069553, cmid0 loss: 0.169150
Epoch (34), Batch(1000/2189), loss: 0.316854, imid loss: 0.079199, imid1 loss: 0.069319, cmid0 loss: 0.168335
Epoch (34), Batch(1200/2189), loss: 0.313689, imid loss: 0.078476, imid1 loss: 0.068675, cmid0 loss: 0.166538
Epoch (34), Batch(1400/2189), loss: 0.313701, imid loss: 0.078257, imid1 loss: 0.068334, cmid0 loss: 0.167110
Epoch (34), Batch(1600/2189), loss: 0.314258, imid loss: 0.079195, imid1 loss: 0.067639, cmid0 loss: 0.167424
Epoch (34), Batch(1800/2189), loss: 0.314929, imid loss: 0.080232, imid1 loss: 0.067465, cmid0 loss: 0.167233
Epoch (34), Batch(2000/2189), loss: 0.313655, imid loss: 0.079949, imid1 loss: 0.067368, cmid0 loss: 0.166338
Train 34, loss: 0.312979
Linear Accuracy : 0.8982982171799028
Start training epoch: (35/100)
Epoch (35), Batch(0/2189), loss: 0.361090, imid loss: 0.115264, imid1 loss: 0.046748, cmid0 loss: 0.199078
Epoch (35), Batch(200/2189), loss: 0.313567, imid loss: 0.076754, imid1 loss: 0.072705, cmid0 loss: 0.164108
Epoch (35), Batch(400/2189), loss: 0.306395, imid loss: 0.074576, imid1 loss: 0.069285, cmid0 loss: 0.162534
Epoch (35), Batch(600/2189), loss: 0.316202, imid loss: 0.077205, imid1 loss: 0.072115, cmid0 loss: 0.166882
Epoch (35), Batch(800/2189), loss: 0.311524, imid loss: 0.076113, imid1 loss: 0.072580, cmid0 loss: 0.162831
Epoch (35), Batch(1000/2189), loss: 0.309498, imid loss: 0.075785, imid1 loss: 0.071253, cmid0 loss: 0.162461
Epoch (35), Batch(1200/2189), loss: 0.307520, imid loss: 0.075935, imid1 loss: 0.070429, cmid0 loss: 0.161155
Epoch (35), Batch(1400/2189), loss: 0.306251, imid loss: 0.075572, imid1 loss: 0.069412, cmid0 loss: 0.161268
Epoch (35), Batch(1600/2189), loss: 0.306997, imid loss: 0.075447, imid1 loss: 0.069676, cmid0 loss: 0.161873
Epoch (35), Batch(1800/2189), loss: 0.307885, imid loss: 0.075508, imid1 loss: 0.070519, cmid0 loss: 0.161859
Epoch (35), Batch(2000/2189), loss: 0.306762, imid loss: 0.075451, imid1 loss: 0.070504, cmid0 loss: 0.160807
Train 35, loss: 0.308778
Linear Accuracy : 0.8962722852512156
==> Saving...
Start training epoch: (36/100)
Epoch (36), Batch(0/2189), loss: 0.438245, imid loss: 0.112749, imid1 loss: 0.151357, cmid0 loss: 0.174139
Epoch (36), Batch(200/2189), loss: 0.300882, imid loss: 0.074233, imid1 loss: 0.070225, cmid0 loss: 0.156424
Epoch (36), Batch(400/2189), loss: 0.300092, imid loss: 0.073975, imid1 loss: 0.069845, cmid0 loss: 0.156272
Epoch (36), Batch(600/2189), loss: 0.299691, imid loss: 0.073207, imid1 loss: 0.068824, cmid0 loss: 0.157659
Epoch (36), Batch(800/2189), loss: 0.301937, imid loss: 0.073309, imid1 loss: 0.070592, cmid0 loss: 0.158036
Epoch (36), Batch(1000/2189), loss: 0.304672, imid loss: 0.074402, imid1 loss: 0.070224, cmid0 loss: 0.160046
Epoch (36), Batch(1200/2189), loss: 0.301950, imid loss: 0.074489, imid1 loss: 0.069406, cmid0 loss: 0.158055
Epoch (36), Batch(1400/2189), loss: 0.302133, imid loss: 0.075065, imid1 loss: 0.068445, cmid0 loss: 0.158623
Epoch (36), Batch(1600/2189), loss: 0.302867, imid loss: 0.075092, imid1 loss: 0.068369, cmid0 loss: 0.159406
Epoch (36), Batch(1800/2189), loss: 0.301961, imid loss: 0.074478, imid1 loss: 0.068278, cmid0 loss: 0.159205
Epoch (36), Batch(2000/2189), loss: 0.299940, imid loss: 0.073995, imid1 loss: 0.067697, cmid0 loss: 0.158248
Train 36, loss: 0.299759
Linear Accuracy : 0.8978930307941653
Start training epoch: (37/100)
Epoch (37), Batch(0/2189), loss: 0.351804, imid loss: 0.183968, imid1 loss: 0.021774, cmid0 loss: 0.146062
Epoch (37), Batch(200/2189), loss: 0.312391, imid loss: 0.076675, imid1 loss: 0.066302, cmid0 loss: 0.169415
Epoch (37), Batch(400/2189), loss: 0.292796, imid loss: 0.074379, imid1 loss: 0.061083, cmid0 loss: 0.157334
Epoch (37), Batch(600/2189), loss: 0.286294, imid loss: 0.069837, imid1 loss: 0.061398, cmid0 loss: 0.155058
Epoch (37), Batch(800/2189), loss: 0.283826, imid loss: 0.069011, imid1 loss: 0.061510, cmid0 loss: 0.153305
Epoch (37), Batch(1000/2189), loss: 0.283628, imid loss: 0.069144, imid1 loss: 0.062931, cmid0 loss: 0.151554
Epoch (37), Batch(1200/2189), loss: 0.284642, imid loss: 0.069959, imid1 loss: 0.062767, cmid0 loss: 0.151917
Epoch (37), Batch(1400/2189), loss: 0.284286, imid loss: 0.070105, imid1 loss: 0.063023, cmid0 loss: 0.151158
Epoch (37), Batch(1600/2189), loss: 0.282409, imid loss: 0.069857, imid1 loss: 0.062567, cmid0 loss: 0.149984
Epoch (37), Batch(1800/2189), loss: 0.283358, imid loss: 0.070612, imid1 loss: 0.062597, cmid0 loss: 0.150148
Epoch (37), Batch(2000/2189), loss: 0.282597, imid loss: 0.070257, imid1 loss: 0.062396, cmid0 loss: 0.149944
Train 37, loss: 0.284766
Linear Accuracy : 0.9015397082658023
Start training epoch: (38/100)
Epoch (38), Batch(0/2189), loss: 0.559334, imid loss: 0.063199, imid1 loss: 0.294597, cmid0 loss: 0.201539
Epoch (38), Batch(200/2189), loss: 0.306847, imid loss: 0.076021, imid1 loss: 0.067691, cmid0 loss: 0.163136
Epoch (38), Batch(400/2189), loss: 0.294306, imid loss: 0.071315, imid1 loss: 0.066313, cmid0 loss: 0.156677
Epoch (38), Batch(600/2189), loss: 0.297497, imid loss: 0.074753, imid1 loss: 0.066529, cmid0 loss: 0.156215
Epoch (38), Batch(800/2189), loss: 0.295751, imid loss: 0.073442, imid1 loss: 0.065854, cmid0 loss: 0.156455
Epoch (38), Batch(1000/2189), loss: 0.292434, imid loss: 0.072510, imid1 loss: 0.065408, cmid0 loss: 0.154516
Epoch (38), Batch(1200/2189), loss: 0.290905, imid loss: 0.071863, imid1 loss: 0.065500, cmid0 loss: 0.153543
Epoch (38), Batch(1400/2189), loss: 0.292858, imid loss: 0.072213, imid1 loss: 0.065494, cmid0 loss: 0.155151
Epoch (38), Batch(1600/2189), loss: 0.290321, imid loss: 0.072015, imid1 loss: 0.064205, cmid0 loss: 0.154101
Epoch (38), Batch(1800/2189), loss: 0.291180, imid loss: 0.072928, imid1 loss: 0.064447, cmid0 loss: 0.153805
Epoch (38), Batch(2000/2189), loss: 0.289818, imid loss: 0.072649, imid1 loss: 0.064112, cmid0 loss: 0.153058
Train 38, loss: 0.288968
Linear Accuracy : 0.9019448946515397
Start training epoch: (39/100)
Epoch (39), Batch(0/2189), loss: 0.552113, imid loss: 0.171337, imid1 loss: 0.140942, cmid0 loss: 0.239834
Epoch (39), Batch(200/2189), loss: 0.268945, imid loss: 0.065759, imid1 loss: 0.063499, cmid0 loss: 0.139686
Epoch (39), Batch(400/2189), loss: 0.280985, imid loss: 0.071001, imid1 loss: 0.062181, cmid0 loss: 0.147803
Epoch (39), Batch(600/2189), loss: 0.279036, imid loss: 0.071177, imid1 loss: 0.060761, cmid0 loss: 0.147099
Epoch (39), Batch(800/2189), loss: 0.281762, imid loss: 0.071269, imid1 loss: 0.062162, cmid0 loss: 0.148331
Epoch (39), Batch(1000/2189), loss: 0.284143, imid loss: 0.071241, imid1 loss: 0.062249, cmid0 loss: 0.150653
Epoch (39), Batch(1200/2189), loss: 0.284533, imid loss: 0.070698, imid1 loss: 0.063627, cmid0 loss: 0.150209
Epoch (39), Batch(1400/2189), loss: 0.281080, imid loss: 0.070262, imid1 loss: 0.062259, cmid0 loss: 0.148560
Epoch (39), Batch(1600/2189), loss: 0.278507, imid loss: 0.069687, imid1 loss: 0.061623, cmid0 loss: 0.147197
Epoch (39), Batch(1800/2189), loss: 0.279290, imid loss: 0.069600, imid1 loss: 0.062351, cmid0 loss: 0.147339
Epoch (39), Batch(2000/2189), loss: 0.279661, imid loss: 0.069430, imid1 loss: 0.062692, cmid0 loss: 0.147539
Train 39, loss: 0.279367
Linear Accuracy : 0.8954619124797407
Start training epoch: (40/100)
Epoch (40), Batch(0/2189), loss: 0.120553, imid loss: 0.024339, imid1 loss: 0.019748, cmid0 loss: 0.076466
Epoch (40), Batch(200/2189), loss: 0.268019, imid loss: 0.061297, imid1 loss: 0.059925, cmid0 loss: 0.146796
Epoch (40), Batch(400/2189), loss: 0.273901, imid loss: 0.066670, imid1 loss: 0.060050, cmid0 loss: 0.147181
Epoch (40), Batch(600/2189), loss: 0.272044, imid loss: 0.065744, imid1 loss: 0.060607, cmid0 loss: 0.145694
Epoch (40), Batch(800/2189), loss: 0.270743, imid loss: 0.066446, imid1 loss: 0.058890, cmid0 loss: 0.145408
Epoch (40), Batch(1000/2189), loss: 0.271800, imid loss: 0.065986, imid1 loss: 0.060070, cmid0 loss: 0.145745
Epoch (40), Batch(1200/2189), loss: 0.273488, imid loss: 0.067600, imid1 loss: 0.060229, cmid0 loss: 0.145659
Epoch (40), Batch(1400/2189), loss: 0.274938, imid loss: 0.068269, imid1 loss: 0.060986, cmid0 loss: 0.145683
Epoch (40), Batch(1600/2189), loss: 0.274605, imid loss: 0.069149, imid1 loss: 0.060664, cmid0 loss: 0.144792
Epoch (40), Batch(1800/2189), loss: 0.275358, imid loss: 0.069606, imid1 loss: 0.060480, cmid0 loss: 0.145272
Epoch (40), Batch(2000/2189), loss: 0.276986, imid loss: 0.069541, imid1 loss: 0.061063, cmid0 loss: 0.146382
Train 40, loss: 0.277211
Linear Accuracy : 0.9003241491085899
==> Saving...
Start training epoch: (41/100)
Epoch (41), Batch(0/2189), loss: 0.084141, imid loss: 0.021353, imid1 loss: 0.016642, cmid0 loss: 0.046146
Epoch (41), Batch(200/2189), loss: 0.275162, imid loss: 0.067076, imid1 loss: 0.062917, cmid0 loss: 0.145169
Epoch (41), Batch(400/2189), loss: 0.274539, imid loss: 0.066594, imid1 loss: 0.064751, cmid0 loss: 0.143194
Epoch (41), Batch(600/2189), loss: 0.266897, imid loss: 0.064630, imid1 loss: 0.061330, cmid0 loss: 0.140936
Epoch (41), Batch(800/2189), loss: 0.260703, imid loss: 0.064385, imid1 loss: 0.058265, cmid0 loss: 0.138053
Epoch (41), Batch(1000/2189), loss: 0.258095, imid loss: 0.064357, imid1 loss: 0.057533, cmid0 loss: 0.136205
Epoch (41), Batch(1200/2189), loss: 0.256841, imid loss: 0.063519, imid1 loss: 0.057286, cmid0 loss: 0.136037
Epoch (41), Batch(1400/2189), loss: 0.260825, imid loss: 0.064814, imid1 loss: 0.058818, cmid0 loss: 0.137193
Epoch (41), Batch(1600/2189), loss: 0.261517, imid loss: 0.064856, imid1 loss: 0.058974, cmid0 loss: 0.137687
Epoch (41), Batch(1800/2189), loss: 0.261658, imid loss: 0.064699, imid1 loss: 0.058684, cmid0 loss: 0.138276
Epoch (41), Batch(2000/2189), loss: 0.262620, imid loss: 0.065130, imid1 loss: 0.058618, cmid0 loss: 0.138872
Train 41, loss: 0.262509
Linear Accuracy : 0.8885737439222042
Start training epoch: (42/100)
Epoch (42), Batch(0/2189), loss: 0.267033, imid loss: 0.021363, imid1 loss: 0.018655, cmid0 loss: 0.227015
Epoch (42), Batch(200/2189), loss: 0.264688, imid loss: 0.066670, imid1 loss: 0.058970, cmid0 loss: 0.139047
Epoch (42), Batch(400/2189), loss: 0.264965, imid loss: 0.064941, imid1 loss: 0.061259, cmid0 loss: 0.138765
Epoch (42), Batch(600/2189), loss: 0.268406, imid loss: 0.065107, imid1 loss: 0.060992, cmid0 loss: 0.142306
Epoch (42), Batch(800/2189), loss: 0.266011, imid loss: 0.063863, imid1 loss: 0.060011, cmid0 loss: 0.142138
Epoch (42), Batch(1000/2189), loss: 0.266221, imid loss: 0.064363, imid1 loss: 0.061118, cmid0 loss: 0.140740
Epoch (42), Batch(1200/2189), loss: 0.266076, imid loss: 0.064120, imid1 loss: 0.060673, cmid0 loss: 0.141282
Epoch (42), Batch(1400/2189), loss: 0.265011, imid loss: 0.063288, imid1 loss: 0.060595, cmid0 loss: 0.141127
Epoch (42), Batch(1600/2189), loss: 0.264447, imid loss: 0.063731, imid1 loss: 0.060139, cmid0 loss: 0.140577
Epoch (42), Batch(1800/2189), loss: 0.266371, imid loss: 0.064605, imid1 loss: 0.060662, cmid0 loss: 0.141105
Epoch (42), Batch(2000/2189), loss: 0.268850, imid loss: 0.065611, imid1 loss: 0.061180, cmid0 loss: 0.142059
Train 42, loss: 0.269377
Linear Accuracy : 0.896677471636953
Start training epoch: (43/100)
Epoch (43), Batch(0/2189), loss: 0.249390, imid loss: 0.057476, imid1 loss: 0.090996, cmid0 loss: 0.100917
Epoch (43), Batch(200/2189), loss: 0.242252, imid loss: 0.062469, imid1 loss: 0.051765, cmid0 loss: 0.128018
Epoch (43), Batch(400/2189), loss: 0.244206, imid loss: 0.062548, imid1 loss: 0.051004, cmid0 loss: 0.130655
Epoch (43), Batch(600/2189), loss: 0.244075, imid loss: 0.061003, imid1 loss: 0.053912, cmid0 loss: 0.129160
Epoch (43), Batch(800/2189), loss: 0.248228, imid loss: 0.061283, imid1 loss: 0.054336, cmid0 loss: 0.132608
Epoch (43), Batch(1000/2189), loss: 0.251526, imid loss: 0.062498, imid1 loss: 0.055677, cmid0 loss: 0.133351
Epoch (43), Batch(1200/2189), loss: 0.255163, imid loss: 0.063674, imid1 loss: 0.056371, cmid0 loss: 0.135118
Epoch (43), Batch(1400/2189), loss: 0.254317, imid loss: 0.063422, imid1 loss: 0.056112, cmid0 loss: 0.134784
Epoch (43), Batch(1600/2189), loss: 0.256057, imid loss: 0.064149, imid1 loss: 0.056600, cmid0 loss: 0.135308
Epoch (43), Batch(1800/2189), loss: 0.258782, imid loss: 0.064966, imid1 loss: 0.057412, cmid0 loss: 0.136405
Epoch (43), Batch(2000/2189), loss: 0.259190, imid loss: 0.065072, imid1 loss: 0.057434, cmid0 loss: 0.136684
Train 43, loss: 0.260074
Linear Accuracy : 0.9015397082658023
Start training epoch: (44/100)
Epoch (44), Batch(0/2189), loss: 0.248731, imid loss: 0.049055, imid1 loss: 0.047422, cmid0 loss: 0.152254
Epoch (44), Batch(200/2189), loss: 0.236107, imid loss: 0.058994, imid1 loss: 0.052481, cmid0 loss: 0.124632
Epoch (44), Batch(400/2189), loss: 0.242372, imid loss: 0.063549, imid1 loss: 0.052290, cmid0 loss: 0.126533
Epoch (44), Batch(600/2189), loss: 0.244893, imid loss: 0.063600, imid1 loss: 0.052978, cmid0 loss: 0.128315
Epoch (44), Batch(800/2189), loss: 0.244776, imid loss: 0.063415, imid1 loss: 0.052959, cmid0 loss: 0.128402
Epoch (44), Batch(1000/2189), loss: 0.246860, imid loss: 0.063353, imid1 loss: 0.054851, cmid0 loss: 0.128656
Epoch (44), Batch(1200/2189), loss: 0.245679, imid loss: 0.063325, imid1 loss: 0.054565, cmid0 loss: 0.127788
Epoch (44), Batch(1400/2189), loss: 0.247194, imid loss: 0.062669, imid1 loss: 0.055956, cmid0 loss: 0.128569
Epoch (44), Batch(1600/2189), loss: 0.246697, imid loss: 0.062711, imid1 loss: 0.055623, cmid0 loss: 0.128363
Epoch (44), Batch(1800/2189), loss: 0.248606, imid loss: 0.063152, imid1 loss: 0.055572, cmid0 loss: 0.129883
Epoch (44), Batch(2000/2189), loss: 0.250752, imid loss: 0.063901, imid1 loss: 0.055834, cmid0 loss: 0.131017
Train 44, loss: 0.251974
Linear Accuracy : 0.8970826580226904
Start training epoch: (45/100)
Epoch (45), Batch(0/2189), loss: 0.117684, imid loss: 0.040758, imid1 loss: 0.033525, cmid0 loss: 0.043401
Epoch (45), Batch(200/2189), loss: 0.242675, imid loss: 0.058052, imid1 loss: 0.056681, cmid0 loss: 0.127943
Epoch (45), Batch(400/2189), loss: 0.237680, imid loss: 0.055392, imid1 loss: 0.057996, cmid0 loss: 0.124292
Epoch (45), Batch(600/2189), loss: 0.239659, imid loss: 0.055719, imid1 loss: 0.058482, cmid0 loss: 0.125458
Epoch (45), Batch(800/2189), loss: 0.237685, imid loss: 0.056684, imid1 loss: 0.056324, cmid0 loss: 0.124676
Epoch (45), Batch(1000/2189), loss: 0.240650, imid loss: 0.057314, imid1 loss: 0.056280, cmid0 loss: 0.127057
Epoch (45), Batch(1200/2189), loss: 0.240476, imid loss: 0.057962, imid1 loss: 0.055237, cmid0 loss: 0.127277
Epoch (45), Batch(1400/2189), loss: 0.239597, imid loss: 0.058419, imid1 loss: 0.054589, cmid0 loss: 0.126589
Epoch (45), Batch(1600/2189), loss: 0.241012, imid loss: 0.058933, imid1 loss: 0.055476, cmid0 loss: 0.126604
Epoch (45), Batch(1800/2189), loss: 0.242571, imid loss: 0.059550, imid1 loss: 0.055488, cmid0 loss: 0.127533
Epoch (45), Batch(2000/2189), loss: 0.244008, imid loss: 0.060144, imid1 loss: 0.055118, cmid0 loss: 0.128747
Train 45, loss: 0.245786
Linear Accuracy : 0.9007293354943274
==> Saving...
Start training epoch: (46/100)
Epoch (46), Batch(0/2189), loss: 0.497289, imid loss: 0.103480, imid1 loss: 0.059448, cmid0 loss: 0.334362
Epoch (46), Batch(200/2189), loss: 0.241486, imid loss: 0.059825, imid1 loss: 0.052897, cmid0 loss: 0.128763
Epoch (46), Batch(400/2189), loss: 0.248994, imid loss: 0.061763, imid1 loss: 0.053928, cmid0 loss: 0.133303
Epoch (46), Batch(600/2189), loss: 0.245341, imid loss: 0.060245, imid1 loss: 0.054399, cmid0 loss: 0.130698
Epoch (46), Batch(800/2189), loss: 0.245290, imid loss: 0.059507, imid1 loss: 0.055713, cmid0 loss: 0.130071
Epoch (46), Batch(1000/2189), loss: 0.246803, imid loss: 0.060354, imid1 loss: 0.055595, cmid0 loss: 0.130854
Epoch (46), Batch(1200/2189), loss: 0.243354, imid loss: 0.060036, imid1 loss: 0.053671, cmid0 loss: 0.129647
Epoch (46), Batch(1400/2189), loss: 0.244138, imid loss: 0.060213, imid1 loss: 0.054052, cmid0 loss: 0.129873
Epoch (46), Batch(1600/2189), loss: 0.245927, imid loss: 0.060361, imid1 loss: 0.054856, cmid0 loss: 0.130709
Epoch (46), Batch(1800/2189), loss: 0.245283, imid loss: 0.060894, imid1 loss: 0.054156, cmid0 loss: 0.130233
Epoch (46), Batch(2000/2189), loss: 0.245531, imid loss: 0.061363, imid1 loss: 0.054249, cmid0 loss: 0.129920
Train 46, loss: 0.246540
Linear Accuracy : 0.9023500810372771
Start training epoch: (47/100)
Epoch (47), Batch(0/2189), loss: 0.098332, imid loss: 0.035153, imid1 loss: 0.012055, cmid0 loss: 0.051123
Epoch (47), Batch(200/2189), loss: 0.239417, imid loss: 0.059666, imid1 loss: 0.056345, cmid0 loss: 0.123406
Epoch (47), Batch(400/2189), loss: 0.242426, imid loss: 0.060922, imid1 loss: 0.057978, cmid0 loss: 0.123526
Epoch (47), Batch(600/2189), loss: 0.232943, imid loss: 0.058346, imid1 loss: 0.053698, cmid0 loss: 0.120900
Epoch (47), Batch(800/2189), loss: 0.235752, imid loss: 0.057704, imid1 loss: 0.055780, cmid0 loss: 0.122268
Epoch (47), Batch(1000/2189), loss: 0.233058, imid loss: 0.057499, imid1 loss: 0.053638, cmid0 loss: 0.121921
Epoch (47), Batch(1200/2189), loss: 0.235019, imid loss: 0.058029, imid1 loss: 0.053742, cmid0 loss: 0.123248
Epoch (47), Batch(1400/2189), loss: 0.235103, imid loss: 0.058307, imid1 loss: 0.053821, cmid0 loss: 0.122974
Epoch (47), Batch(1600/2189), loss: 0.233837, imid loss: 0.058139, imid1 loss: 0.053095, cmid0 loss: 0.122604
Epoch (47), Batch(1800/2189), loss: 0.235113, imid loss: 0.058329, imid1 loss: 0.053165, cmid0 loss: 0.123619
Epoch (47), Batch(2000/2189), loss: 0.237263, imid loss: 0.059082, imid1 loss: 0.053487, cmid0 loss: 0.124694
Train 47, loss: 0.236801
Linear Accuracy : 0.9007293354943274
Start training epoch: (48/100)
Epoch (48), Batch(0/2189), loss: 0.128269, imid loss: 0.014936, imid1 loss: 0.045185, cmid0 loss: 0.068149
Epoch (48), Batch(200/2189), loss: 0.221044, imid loss: 0.059233, imid1 loss: 0.046465, cmid0 loss: 0.115346
Epoch (48), Batch(400/2189), loss: 0.232333, imid loss: 0.059428, imid1 loss: 0.051062, cmid0 loss: 0.121843
Epoch (48), Batch(600/2189), loss: 0.236368, imid loss: 0.059105, imid1 loss: 0.052317, cmid0 loss: 0.124946
Epoch (48), Batch(800/2189), loss: 0.239938, imid loss: 0.059900, imid1 loss: 0.054235, cmid0 loss: 0.125803
Epoch (48), Batch(1000/2189), loss: 0.238366, imid loss: 0.058700, imid1 loss: 0.054164, cmid0 loss: 0.125502
Epoch (48), Batch(1200/2189), loss: 0.235782, imid loss: 0.057837, imid1 loss: 0.053498, cmid0 loss: 0.124446
Epoch (48), Batch(1400/2189), loss: 0.237466, imid loss: 0.058518, imid1 loss: 0.053725, cmid0 loss: 0.125223
Epoch (48), Batch(1600/2189), loss: 0.235776, imid loss: 0.058694, imid1 loss: 0.052736, cmid0 loss: 0.124346
Epoch (48), Batch(1800/2189), loss: 0.235121, imid loss: 0.058853, imid1 loss: 0.052419, cmid0 loss: 0.123850
Epoch (48), Batch(2000/2189), loss: 0.234139, imid loss: 0.058571, imid1 loss: 0.052030, cmid0 loss: 0.123538
Train 48, loss: 0.234613
Linear Accuracy : 0.8954619124797407
Start training epoch: (49/100)
Epoch (49), Batch(0/2189), loss: 0.229929, imid loss: 0.059389, imid1 loss: 0.016406, cmid0 loss: 0.154134
Epoch (49), Batch(200/2189), loss: 0.229723, imid loss: 0.053977, imid1 loss: 0.054299, cmid0 loss: 0.121447
Epoch (49), Batch(400/2189), loss: 0.242573, imid loss: 0.060552, imid1 loss: 0.055372, cmid0 loss: 0.126649
Epoch (49), Batch(600/2189), loss: 0.236095, imid loss: 0.060134, imid1 loss: 0.053056, cmid0 loss: 0.122906
Epoch (49), Batch(800/2189), loss: 0.233655, imid loss: 0.059332, imid1 loss: 0.051842, cmid0 loss: 0.122480
Epoch (49), Batch(1000/2189), loss: 0.227645, imid loss: 0.057318, imid1 loss: 0.051095, cmid0 loss: 0.119233
Epoch (49), Batch(1200/2189), loss: 0.227659, imid loss: 0.057457, imid1 loss: 0.050728, cmid0 loss: 0.119474
Epoch (49), Batch(1400/2189), loss: 0.225926, imid loss: 0.057226, imid1 loss: 0.050044, cmid0 loss: 0.118655
Epoch (49), Batch(1600/2189), loss: 0.224999, imid loss: 0.057210, imid1 loss: 0.049710, cmid0 loss: 0.118079
Epoch (49), Batch(1800/2189), loss: 0.229326, imid loss: 0.058241, imid1 loss: 0.050441, cmid0 loss: 0.120644
Epoch (49), Batch(2000/2189), loss: 0.229330, imid loss: 0.058073, imid1 loss: 0.050764, cmid0 loss: 0.120493
Train 49, loss: 0.230805
Linear Accuracy : 0.9003241491085899
Start training epoch: (50/100)
Epoch (50), Batch(0/2189), loss: 0.336552, imid loss: 0.024814, imid1 loss: 0.026144, cmid0 loss: 0.285595
Epoch (50), Batch(200/2189), loss: 0.233712, imid loss: 0.057281, imid1 loss: 0.052906, cmid0 loss: 0.123525
Epoch (50), Batch(400/2189), loss: 0.227135, imid loss: 0.055997, imid1 loss: 0.050455, cmid0 loss: 0.120683
Epoch (50), Batch(600/2189), loss: 0.227324, imid loss: 0.056317, imid1 loss: 0.051259, cmid0 loss: 0.119748
Epoch (50), Batch(800/2189), loss: 0.232219, imid loss: 0.057851, imid1 loss: 0.053045, cmid0 loss: 0.121323
Epoch (50), Batch(1000/2189), loss: 0.230882, imid loss: 0.057725, imid1 loss: 0.052185, cmid0 loss: 0.120972
Epoch (50), Batch(1200/2189), loss: 0.227405, imid loss: 0.056525, imid1 loss: 0.051895, cmid0 loss: 0.118985
Epoch (50), Batch(1400/2189), loss: 0.227322, imid loss: 0.056174, imid1 loss: 0.051658, cmid0 loss: 0.119490
Epoch (50), Batch(1600/2189), loss: 0.224740, imid loss: 0.056122, imid1 loss: 0.050797, cmid0 loss: 0.117821
Epoch (50), Batch(1800/2189), loss: 0.225195, imid loss: 0.057135, imid1 loss: 0.050457, cmid0 loss: 0.117603
Epoch (50), Batch(2000/2189), loss: 0.224801, imid loss: 0.057016, imid1 loss: 0.050006, cmid0 loss: 0.117779
Train 50, loss: 0.225606
Linear Accuracy : 0.8974878444084279
==> Saving...
Start training epoch: (51/100)
Epoch (51), Batch(0/2189), loss: 0.611136, imid loss: 0.158577, imid1 loss: 0.193413, cmid0 loss: 0.259146
Epoch (51), Batch(200/2189), loss: 0.208901, imid loss: 0.055548, imid1 loss: 0.043307, cmid0 loss: 0.110046
Epoch (51), Batch(400/2189), loss: 0.202893, imid loss: 0.053682, imid1 loss: 0.044773, cmid0 loss: 0.104438
Epoch (51), Batch(600/2189), loss: 0.211043, imid loss: 0.053822, imid1 loss: 0.046118, cmid0 loss: 0.111103
Epoch (51), Batch(800/2189), loss: 0.219135, imid loss: 0.055777, imid1 loss: 0.048864, cmid0 loss: 0.114495
Epoch (51), Batch(1000/2189), loss: 0.217687, imid loss: 0.055058, imid1 loss: 0.048407, cmid0 loss: 0.114222
Epoch (51), Batch(1200/2189), loss: 0.217539, imid loss: 0.054781, imid1 loss: 0.048411, cmid0 loss: 0.114346
Epoch (51), Batch(1400/2189), loss: 0.218322, imid loss: 0.054763, imid1 loss: 0.048445, cmid0 loss: 0.115115
Epoch (51), Batch(1600/2189), loss: 0.216669, imid loss: 0.054306, imid1 loss: 0.048124, cmid0 loss: 0.114239
Epoch (51), Batch(1800/2189), loss: 0.217849, imid loss: 0.054720, imid1 loss: 0.048589, cmid0 loss: 0.114539
Epoch (51), Batch(2000/2189), loss: 0.217354, imid loss: 0.054225, imid1 loss: 0.048909, cmid0 loss: 0.114220
Train 51, loss: 0.217295
Linear Accuracy : 0.8954619124797407
Start training epoch: (52/100)
Epoch (52), Batch(0/2189), loss: 0.090421, imid loss: 0.010089, imid1 loss: 0.021731, cmid0 loss: 0.058601
Epoch (52), Batch(200/2189), loss: 0.213677, imid loss: 0.056531, imid1 loss: 0.046453, cmid0 loss: 0.110692
Epoch (52), Batch(400/2189), loss: 0.202677, imid loss: 0.052436, imid1 loss: 0.043493, cmid0 loss: 0.106748
Epoch (52), Batch(600/2189), loss: 0.210206, imid loss: 0.053995, imid1 loss: 0.045596, cmid0 loss: 0.110616
Epoch (52), Batch(800/2189), loss: 0.212920, imid loss: 0.053977, imid1 loss: 0.046971, cmid0 loss: 0.111973
Epoch (52), Batch(1000/2189), loss: 0.212327, imid loss: 0.053251, imid1 loss: 0.046010, cmid0 loss: 0.113066
Epoch (52), Batch(1200/2189), loss: 0.214116, imid loss: 0.053600, imid1 loss: 0.046545, cmid0 loss: 0.113972
Epoch (52), Batch(1400/2189), loss: 0.214456, imid loss: 0.053677, imid1 loss: 0.047233, cmid0 loss: 0.113547
Epoch (52), Batch(1600/2189), loss: 0.214245, imid loss: 0.053515, imid1 loss: 0.047343, cmid0 loss: 0.113388
Epoch (52), Batch(1800/2189), loss: 0.214249, imid loss: 0.053477, imid1 loss: 0.047606, cmid0 loss: 0.113165
Epoch (52), Batch(2000/2189), loss: 0.213400, imid loss: 0.053606, imid1 loss: 0.046765, cmid0 loss: 0.113029
Train 52, loss: 0.213766
Linear Accuracy : 0.8978930307941653
Start training epoch: (53/100)
Epoch (53), Batch(0/2189), loss: 0.171101, imid loss: 0.032897, imid1 loss: 0.056550, cmid0 loss: 0.081654
Epoch (53), Batch(200/2189), loss: 0.208535, imid loss: 0.049464, imid1 loss: 0.050467, cmid0 loss: 0.108604
Epoch (53), Batch(400/2189), loss: 0.213186, imid loss: 0.051843, imid1 loss: 0.049970, cmid0 loss: 0.111374
Epoch (53), Batch(600/2189), loss: 0.217379, imid loss: 0.052862, imid1 loss: 0.051953, cmid0 loss: 0.112564
Epoch (53), Batch(800/2189), loss: 0.214354, imid loss: 0.052373, imid1 loss: 0.050804, cmid0 loss: 0.111176
Epoch (53), Batch(1000/2189), loss: 0.212793, imid loss: 0.052627, imid1 loss: 0.049663, cmid0 loss: 0.110503
Epoch (53), Batch(1200/2189), loss: 0.213023, imid loss: 0.053694, imid1 loss: 0.049088, cmid0 loss: 0.110242
Epoch (53), Batch(1400/2189), loss: 0.213023, imid loss: 0.053909, imid1 loss: 0.048739, cmid0 loss: 0.110376
Epoch (53), Batch(1600/2189), loss: 0.212135, imid loss: 0.054069, imid1 loss: 0.048061, cmid0 loss: 0.110005
Epoch (53), Batch(1800/2189), loss: 0.213354, imid loss: 0.054303, imid1 loss: 0.048690, cmid0 loss: 0.110361
Epoch (53), Batch(2000/2189), loss: 0.214634, imid loss: 0.054266, imid1 loss: 0.049170, cmid0 loss: 0.111198
Train 53, loss: 0.215022
Linear Accuracy : 0.8962722852512156
Start training epoch: (54/100)
Epoch (54), Batch(0/2189), loss: 0.145143, imid loss: 0.032426, imid1 loss: 0.019649, cmid0 loss: 0.093068
Epoch (54), Batch(200/2189), loss: 0.189122, imid loss: 0.048840, imid1 loss: 0.046463, cmid0 loss: 0.093819
Epoch (54), Batch(400/2189), loss: 0.189565, imid loss: 0.049155, imid1 loss: 0.044064, cmid0 loss: 0.096346
Epoch (54), Batch(600/2189), loss: 0.194679, imid loss: 0.050171, imid1 loss: 0.045029, cmid0 loss: 0.099479
Epoch (54), Batch(800/2189), loss: 0.200303, imid loss: 0.051923, imid1 loss: 0.045692, cmid0 loss: 0.102688
Epoch (54), Batch(1000/2189), loss: 0.200336, imid loss: 0.051846, imid1 loss: 0.045553, cmid0 loss: 0.102937
Epoch (54), Batch(1200/2189), loss: 0.197286, imid loss: 0.050914, imid1 loss: 0.044469, cmid0 loss: 0.101902
Epoch (54), Batch(1400/2189), loss: 0.196566, imid loss: 0.050867, imid1 loss: 0.043550, cmid0 loss: 0.102149
Epoch (54), Batch(1600/2189), loss: 0.201982, imid loss: 0.051778, imid1 loss: 0.045028, cmid0 loss: 0.105175
Epoch (54), Batch(1800/2189), loss: 0.203950, imid loss: 0.051923, imid1 loss: 0.045723, cmid0 loss: 0.106304
Epoch (54), Batch(2000/2189), loss: 0.203208, imid loss: 0.051853, imid1 loss: 0.045357, cmid0 loss: 0.105997
Train 54, loss: 0.204718
Linear Accuracy : 0.8974878444084279
Start training epoch: (55/100)
Epoch (55), Batch(0/2189), loss: 0.072679, imid loss: 0.017773, imid1 loss: 0.015639, cmid0 loss: 0.039268
Epoch (55), Batch(200/2189), loss: 0.199420, imid loss: 0.055530, imid1 loss: 0.044638, cmid0 loss: 0.099251
Epoch (55), Batch(400/2189), loss: 0.196609, imid loss: 0.052720, imid1 loss: 0.045350, cmid0 loss: 0.098539
Epoch (55), Batch(600/2189), loss: 0.200678, imid loss: 0.051813, imid1 loss: 0.047016, cmid0 loss: 0.101849
Epoch (55), Batch(800/2189), loss: 0.205857, imid loss: 0.053118, imid1 loss: 0.046767, cmid0 loss: 0.105972
Epoch (55), Batch(1000/2189), loss: 0.205210, imid loss: 0.052561, imid1 loss: 0.046099, cmid0 loss: 0.106550
Epoch (55), Batch(1200/2189), loss: 0.204436, imid loss: 0.052714, imid1 loss: 0.045415, cmid0 loss: 0.106307
Epoch (55), Batch(1400/2189), loss: 0.203657, imid loss: 0.052894, imid1 loss: 0.044948, cmid0 loss: 0.105816
Epoch (55), Batch(1600/2189), loss: 0.202217, imid loss: 0.052229, imid1 loss: 0.044914, cmid0 loss: 0.105074
Epoch (55), Batch(1800/2189), loss: 0.201762, imid loss: 0.051921, imid1 loss: 0.044983, cmid0 loss: 0.104858
Epoch (55), Batch(2000/2189), loss: 0.201030, imid loss: 0.051250, imid1 loss: 0.045126, cmid0 loss: 0.104654
Train 55, loss: 0.201012
Linear Accuracy : 0.893030794165316
==> Saving...
Start training epoch: (56/100)
Epoch (56), Batch(0/2189), loss: 0.193356, imid loss: 0.018843, imid1 loss: 0.009207, cmid0 loss: 0.165306
Epoch (56), Batch(200/2189), loss: 0.212013, imid loss: 0.055246, imid1 loss: 0.048786, cmid0 loss: 0.107981
Epoch (56), Batch(400/2189), loss: 0.196845, imid loss: 0.051595, imid1 loss: 0.042468, cmid0 loss: 0.102783
Epoch (56), Batch(600/2189), loss: 0.194656, imid loss: 0.049965, imid1 loss: 0.043986, cmid0 loss: 0.100706
Epoch (56), Batch(800/2189), loss: 0.201149, imid loss: 0.051692, imid1 loss: 0.045959, cmid0 loss: 0.103498
Epoch (56), Batch(1000/2189), loss: 0.202493, imid loss: 0.053111, imid1 loss: 0.045674, cmid0 loss: 0.103708
Epoch (56), Batch(1200/2189), loss: 0.201780, imid loss: 0.052940, imid1 loss: 0.044929, cmid0 loss: 0.103911
Epoch (56), Batch(1400/2189), loss: 0.204341, imid loss: 0.053047, imid1 loss: 0.045757, cmid0 loss: 0.105536
Epoch (56), Batch(1600/2189), loss: 0.202597, imid loss: 0.052572, imid1 loss: 0.045185, cmid0 loss: 0.104839
Epoch (56), Batch(1800/2189), loss: 0.204208, imid loss: 0.052791, imid1 loss: 0.045562, cmid0 loss: 0.105855
Epoch (56), Batch(2000/2189), loss: 0.203459, imid loss: 0.052220, imid1 loss: 0.045610, cmid0 loss: 0.105629
Train 56, loss: 0.203719
Linear Accuracy : 0.8962722852512156
Start training epoch: (57/100)
Epoch (57), Batch(0/2189), loss: 0.135992, imid loss: 0.041017, imid1 loss: 0.019406, cmid0 loss: 0.075569
Epoch (57), Batch(200/2189), loss: 0.187709, imid loss: 0.047264, imid1 loss: 0.042875, cmid0 loss: 0.097570
Epoch (57), Batch(400/2189), loss: 0.192883, imid loss: 0.049401, imid1 loss: 0.042809, cmid0 loss: 0.100672
Epoch (57), Batch(600/2189), loss: 0.196489, imid loss: 0.050440, imid1 loss: 0.044359, cmid0 loss: 0.101691
Epoch (57), Batch(800/2189), loss: 0.195552, imid loss: 0.050023, imid1 loss: 0.044015, cmid0 loss: 0.101514
Epoch (57), Batch(1000/2189), loss: 0.194278, imid loss: 0.049283, imid1 loss: 0.043382, cmid0 loss: 0.101614
Epoch (57), Batch(1200/2189), loss: 0.194898, imid loss: 0.050005, imid1 loss: 0.043461, cmid0 loss: 0.101431
Epoch (57), Batch(1400/2189), loss: 0.195545, imid loss: 0.050167, imid1 loss: 0.043464, cmid0 loss: 0.101914
Epoch (57), Batch(1600/2189), loss: 0.194744, imid loss: 0.049722, imid1 loss: 0.043632, cmid0 loss: 0.101390
Epoch (57), Batch(1800/2189), loss: 0.195571, imid loss: 0.049734, imid1 loss: 0.043907, cmid0 loss: 0.101930
Epoch (57), Batch(2000/2189), loss: 0.195854, imid loss: 0.049523, imid1 loss: 0.044074, cmid0 loss: 0.102258
Train 57, loss: 0.197582
Linear Accuracy : 0.8926256077795786
Start training epoch: (58/100)
Epoch (58), Batch(0/2189), loss: 0.266639, imid loss: 0.072475, imid1 loss: 0.121351, cmid0 loss: 0.072813
Epoch (58), Batch(200/2189), loss: 0.202039, imid loss: 0.055643, imid1 loss: 0.041019, cmid0 loss: 0.105377
Epoch (58), Batch(400/2189), loss: 0.202925, imid loss: 0.053826, imid1 loss: 0.044678, cmid0 loss: 0.104420
Epoch (58), Batch(600/2189), loss: 0.197860, imid loss: 0.053518, imid1 loss: 0.042722, cmid0 loss: 0.101619
Epoch (58), Batch(800/2189), loss: 0.196880, imid loss: 0.052732, imid1 loss: 0.043625, cmid0 loss: 0.100523
Epoch (58), Batch(1000/2189), loss: 0.197562, imid loss: 0.052248, imid1 loss: 0.043856, cmid0 loss: 0.101458
Epoch (58), Batch(1200/2189), loss: 0.196728, imid loss: 0.052399, imid1 loss: 0.043210, cmid0 loss: 0.101119
Epoch (58), Batch(1400/2189), loss: 0.193758, imid loss: 0.051189, imid1 loss: 0.043106, cmid0 loss: 0.099464
Epoch (58), Batch(1600/2189), loss: 0.192888, imid loss: 0.050431, imid1 loss: 0.043046, cmid0 loss: 0.099411
Epoch (58), Batch(1800/2189), loss: 0.192500, imid loss: 0.050184, imid1 loss: 0.042975, cmid0 loss: 0.099340
Epoch (58), Batch(2000/2189), loss: 0.193083, imid loss: 0.050154, imid1 loss: 0.043071, cmid0 loss: 0.099859
Train 58, loss: 0.192550
Linear Accuracy : 0.8999189627228525
Start training epoch: (59/100)
Epoch (59), Batch(0/2189), loss: 0.282864, imid loss: 0.114832, imid1 loss: 0.042478, cmid0 loss: 0.125554
Epoch (59), Batch(200/2189), loss: 0.184239, imid loss: 0.047670, imid1 loss: 0.042049, cmid0 loss: 0.094520
Epoch (59), Batch(400/2189), loss: 0.182299, imid loss: 0.047606, imid1 loss: 0.039833, cmid0 loss: 0.094860
Epoch (59), Batch(600/2189), loss: 0.186058, imid loss: 0.048432, imid1 loss: 0.040457, cmid0 loss: 0.097169
Epoch (59), Batch(800/2189), loss: 0.184406, imid loss: 0.047142, imid1 loss: 0.040219, cmid0 loss: 0.097045
Epoch (59), Batch(1000/2189), loss: 0.185744, imid loss: 0.048078, imid1 loss: 0.040900, cmid0 loss: 0.096767
Epoch (59), Batch(1200/2189), loss: 0.186524, imid loss: 0.047944, imid1 loss: 0.041410, cmid0 loss: 0.097170
Epoch (59), Batch(1400/2189), loss: 0.184459, imid loss: 0.047273, imid1 loss: 0.041180, cmid0 loss: 0.096006
Epoch (59), Batch(1600/2189), loss: 0.187634, imid loss: 0.048878, imid1 loss: 0.041675, cmid0 loss: 0.097081
Epoch (59), Batch(1800/2189), loss: 0.188200, imid loss: 0.048771, imid1 loss: 0.042327, cmid0 loss: 0.097102
Epoch (59), Batch(2000/2189), loss: 0.188344, imid loss: 0.048841, imid1 loss: 0.042501, cmid0 loss: 0.097002
Train 59, loss: 0.188856
Linear Accuracy : 0.899513776337115
Start training epoch: (60/100)
Epoch (60), Batch(0/2189), loss: 0.075599, imid loss: 0.016051, imid1 loss: 0.009594, cmid0 loss: 0.049953
Epoch (60), Batch(200/2189), loss: 0.183552, imid loss: 0.047984, imid1 loss: 0.041386, cmid0 loss: 0.094182
Epoch (60), Batch(400/2189), loss: 0.181153, imid loss: 0.046155, imid1 loss: 0.043720, cmid0 loss: 0.091278
Epoch (60), Batch(600/2189), loss: 0.182842, imid loss: 0.047402, imid1 loss: 0.042751, cmid0 loss: 0.092689
Epoch (60), Batch(800/2189), loss: 0.187325, imid loss: 0.048974, imid1 loss: 0.041916, cmid0 loss: 0.096435
Epoch (60), Batch(1000/2189), loss: 0.189546, imid loss: 0.049530, imid1 loss: 0.043041, cmid0 loss: 0.096975
Epoch (60), Batch(1200/2189), loss: 0.189243, imid loss: 0.048849, imid1 loss: 0.043084, cmid0 loss: 0.097310
Epoch (60), Batch(1400/2189), loss: 0.187815, imid loss: 0.048662, imid1 loss: 0.042621, cmid0 loss: 0.096532
Epoch (60), Batch(1600/2189), loss: 0.190766, imid loss: 0.049499, imid1 loss: 0.043372, cmid0 loss: 0.097895
Epoch (60), Batch(1800/2189), loss: 0.188977, imid loss: 0.048791, imid1 loss: 0.042612, cmid0 loss: 0.097573
Epoch (60), Batch(2000/2189), loss: 0.189778, imid loss: 0.048635, imid1 loss: 0.043066, cmid0 loss: 0.098077
Train 60, loss: 0.189972
Linear Accuracy : 0.903160453808752
==> Saving...
Start training epoch: (61/100)
Epoch (61), Batch(0/2189), loss: 0.044547, imid loss: 0.013371, imid1 loss: 0.007464, cmid0 loss: 0.023711
Epoch (61), Batch(200/2189), loss: 0.188827, imid loss: 0.051013, imid1 loss: 0.044203, cmid0 loss: 0.093610
Epoch (61), Batch(400/2189), loss: 0.184226, imid loss: 0.047034, imid1 loss: 0.043560, cmid0 loss: 0.093632
Epoch (61), Batch(600/2189), loss: 0.185794, imid loss: 0.047063, imid1 loss: 0.043918, cmid0 loss: 0.094814
Epoch (61), Batch(800/2189), loss: 0.190160, imid loss: 0.048516, imid1 loss: 0.044655, cmid0 loss: 0.096989
Epoch (61), Batch(1000/2189), loss: 0.187709, imid loss: 0.048242, imid1 loss: 0.043498, cmid0 loss: 0.095969
Epoch (61), Batch(1200/2189), loss: 0.186231, imid loss: 0.047542, imid1 loss: 0.043207, cmid0 loss: 0.095482
Epoch (61), Batch(1400/2189), loss: 0.184512, imid loss: 0.047247, imid1 loss: 0.042481, cmid0 loss: 0.094784
Epoch (61), Batch(1600/2189), loss: 0.183409, imid loss: 0.047019, imid1 loss: 0.042074, cmid0 loss: 0.094316
Epoch (61), Batch(1800/2189), loss: 0.181336, imid loss: 0.046452, imid1 loss: 0.041521, cmid0 loss: 0.093363
Epoch (61), Batch(2000/2189), loss: 0.181928, imid loss: 0.046817, imid1 loss: 0.041167, cmid0 loss: 0.093943
Train 61, loss: 0.181658
Linear Accuracy : 0.9039708265802269
Start training epoch: (62/100)
Epoch (62), Batch(0/2189), loss: 0.027968, imid loss: 0.006162, imid1 loss: 0.003967, cmid0 loss: 0.017839
Epoch (62), Batch(200/2189), loss: 0.172991, imid loss: 0.046182, imid1 loss: 0.038939, cmid0 loss: 0.087870
Epoch (62), Batch(400/2189), loss: 0.178854, imid loss: 0.047323, imid1 loss: 0.038887, cmid0 loss: 0.092644
Epoch (62), Batch(600/2189), loss: 0.179968, imid loss: 0.047228, imid1 loss: 0.039154, cmid0 loss: 0.093586
Epoch (62), Batch(800/2189), loss: 0.184695, imid loss: 0.048533, imid1 loss: 0.039649, cmid0 loss: 0.096514
Epoch (62), Batch(1000/2189), loss: 0.185581, imid loss: 0.048795, imid1 loss: 0.039969, cmid0 loss: 0.096817
Epoch (62), Batch(1200/2189), loss: 0.183299, imid loss: 0.047713, imid1 loss: 0.039504, cmid0 loss: 0.096082
Epoch (62), Batch(1400/2189), loss: 0.182980, imid loss: 0.047653, imid1 loss: 0.039234, cmid0 loss: 0.096093
Epoch (62), Batch(1600/2189), loss: 0.183552, imid loss: 0.048109, imid1 loss: 0.039244, cmid0 loss: 0.096199
Epoch (62), Batch(1800/2189), loss: 0.183656, imid loss: 0.048268, imid1 loss: 0.039305, cmid0 loss: 0.096084
Epoch (62), Batch(2000/2189), loss: 0.182347, imid loss: 0.047921, imid1 loss: 0.039495, cmid0 loss: 0.094932
Train 62, loss: 0.182204
Linear Accuracy : 0.9015397082658023
Start training epoch: (63/100)
Epoch (63), Batch(0/2189), loss: 0.097046, imid loss: 0.022482, imid1 loss: 0.016671, cmid0 loss: 0.057892
Epoch (63), Batch(200/2189), loss: 0.175919, imid loss: 0.046558, imid1 loss: 0.037002, cmid0 loss: 0.092359
Epoch (63), Batch(400/2189), loss: 0.170434, imid loss: 0.045745, imid1 loss: 0.037990, cmid0 loss: 0.086699
Epoch (63), Batch(600/2189), loss: 0.169608, imid loss: 0.045931, imid1 loss: 0.037560, cmid0 loss: 0.086117
Epoch (63), Batch(800/2189), loss: 0.168422, imid loss: 0.044616, imid1 loss: 0.037331, cmid0 loss: 0.086474
Epoch (63), Batch(1000/2189), loss: 0.170765, imid loss: 0.044887, imid1 loss: 0.037137, cmid0 loss: 0.088741
Epoch (63), Batch(1200/2189), loss: 0.174580, imid loss: 0.045881, imid1 loss: 0.037943, cmid0 loss: 0.090756
Epoch (63), Batch(1400/2189), loss: 0.174045, imid loss: 0.045485, imid1 loss: 0.038076, cmid0 loss: 0.090484
Epoch (63), Batch(1600/2189), loss: 0.174928, imid loss: 0.045806, imid1 loss: 0.038052, cmid0 loss: 0.091070
Epoch (63), Batch(1800/2189), loss: 0.175288, imid loss: 0.045374, imid1 loss: 0.038626, cmid0 loss: 0.091288
Epoch (63), Batch(2000/2189), loss: 0.176308, imid loss: 0.045556, imid1 loss: 0.038795, cmid0 loss: 0.091957
Train 63, loss: 0.177078
Linear Accuracy : 0.896677471636953
Start training epoch: (64/100)
Epoch (64), Batch(0/2189), loss: 0.223800, imid loss: 0.021091, imid1 loss: 0.006432, cmid0 loss: 0.196278
Epoch (64), Batch(200/2189), loss: 0.171599, imid loss: 0.042818, imid1 loss: 0.040500, cmid0 loss: 0.088281
Epoch (64), Batch(400/2189), loss: 0.168659, imid loss: 0.042876, imid1 loss: 0.039285, cmid0 loss: 0.086498
Epoch (64), Batch(600/2189), loss: 0.167741, imid loss: 0.043566, imid1 loss: 0.039258, cmid0 loss: 0.084918
Epoch (64), Batch(800/2189), loss: 0.169757, imid loss: 0.044270, imid1 loss: 0.039204, cmid0 loss: 0.086283
Epoch (64), Batch(1000/2189), loss: 0.168680, imid loss: 0.043521, imid1 loss: 0.038866, cmid0 loss: 0.086293
Epoch (64), Batch(1200/2189), loss: 0.169614, imid loss: 0.044272, imid1 loss: 0.038613, cmid0 loss: 0.086729
Epoch (64), Batch(1400/2189), loss: 0.169623, imid loss: 0.044413, imid1 loss: 0.038575, cmid0 loss: 0.086636
Epoch (64), Batch(1600/2189), loss: 0.170809, imid loss: 0.044202, imid1 loss: 0.038957, cmid0 loss: 0.087650
Epoch (64), Batch(1800/2189), loss: 0.170690, imid loss: 0.043883, imid1 loss: 0.038769, cmid0 loss: 0.088037
Epoch (64), Batch(2000/2189), loss: 0.170538, imid loss: 0.043985, imid1 loss: 0.038617, cmid0 loss: 0.087936
Train 64, loss: 0.170475
Linear Accuracy : 0.8978930307941653
Start training epoch: (65/100)
Epoch (65), Batch(0/2189), loss: 0.220039, imid loss: 0.076949, imid1 loss: 0.028867, cmid0 loss: 0.114222
Epoch (65), Batch(200/2189), loss: 0.170834, imid loss: 0.044229, imid1 loss: 0.040456, cmid0 loss: 0.086149
Epoch (65), Batch(400/2189), loss: 0.166949, imid loss: 0.043296, imid1 loss: 0.036904, cmid0 loss: 0.086749
Epoch (65), Batch(600/2189), loss: 0.168231, imid loss: 0.043488, imid1 loss: 0.037484, cmid0 loss: 0.087260
Epoch (65), Batch(800/2189), loss: 0.169720, imid loss: 0.043993, imid1 loss: 0.038533, cmid0 loss: 0.087194
Epoch (65), Batch(1000/2189), loss: 0.172625, imid loss: 0.045124, imid1 loss: 0.038426, cmid0 loss: 0.089075
Epoch (65), Batch(1200/2189), loss: 0.173722, imid loss: 0.045018, imid1 loss: 0.039148, cmid0 loss: 0.089555
Epoch (65), Batch(1400/2189), loss: 0.173024, imid loss: 0.045136, imid1 loss: 0.038916, cmid0 loss: 0.088972
Epoch (65), Batch(1600/2189), loss: 0.172887, imid loss: 0.045174, imid1 loss: 0.038422, cmid0 loss: 0.089292
Epoch (65), Batch(1800/2189), loss: 0.171130, imid loss: 0.045013, imid1 loss: 0.037701, cmid0 loss: 0.088416
Epoch (65), Batch(2000/2189), loss: 0.173575, imid loss: 0.045701, imid1 loss: 0.038310, cmid0 loss: 0.089564
Train 65, loss: 0.173207
Linear Accuracy : 0.8958670988654781
==> Saving...
Start training epoch: (66/100)
Epoch (66), Batch(0/2189), loss: 0.098469, imid loss: 0.059839, imid1 loss: 0.006926, cmid0 loss: 0.031703
Epoch (66), Batch(200/2189), loss: 0.165521, imid loss: 0.043624, imid1 loss: 0.035979, cmid0 loss: 0.085919
Epoch (66), Batch(400/2189), loss: 0.161822, imid loss: 0.042322, imid1 loss: 0.034980, cmid0 loss: 0.084520
Epoch (66), Batch(600/2189), loss: 0.164641, imid loss: 0.043415, imid1 loss: 0.035494, cmid0 loss: 0.085733
Epoch (66), Batch(800/2189), loss: 0.164087, imid loss: 0.043009, imid1 loss: 0.035875, cmid0 loss: 0.085203
Epoch (66), Batch(1000/2189), loss: 0.164190, imid loss: 0.042686, imid1 loss: 0.037237, cmid0 loss: 0.084267
Epoch (66), Batch(1200/2189), loss: 0.163746, imid loss: 0.042090, imid1 loss: 0.037194, cmid0 loss: 0.084461
Epoch (66), Batch(1400/2189), loss: 0.165784, imid loss: 0.042203, imid1 loss: 0.038133, cmid0 loss: 0.085449
Epoch (66), Batch(1600/2189), loss: 0.166945, imid loss: 0.042812, imid1 loss: 0.038431, cmid0 loss: 0.085702
Epoch (66), Batch(1800/2189), loss: 0.167016, imid loss: 0.042861, imid1 loss: 0.038101, cmid0 loss: 0.086054
Epoch (66), Batch(2000/2189), loss: 0.168205, imid loss: 0.043411, imid1 loss: 0.038216, cmid0 loss: 0.086577
Train 66, loss: 0.169457
Linear Accuracy : 0.9003241491085899
Start training epoch: (67/100)
Epoch (67), Batch(0/2189), loss: 0.104327, imid loss: 0.028331, imid1 loss: 0.041696, cmid0 loss: 0.034300
Epoch (67), Batch(200/2189), loss: 0.162113, imid loss: 0.043540, imid1 loss: 0.034606, cmid0 loss: 0.083967
Epoch (67), Batch(400/2189), loss: 0.163702, imid loss: 0.044014, imid1 loss: 0.035291, cmid0 loss: 0.084397
Epoch (67), Batch(600/2189), loss: 0.162078, imid loss: 0.043437, imid1 loss: 0.036003, cmid0 loss: 0.082638
Epoch (67), Batch(800/2189), loss: 0.160971, imid loss: 0.042582, imid1 loss: 0.035737, cmid0 loss: 0.082652
Epoch (67), Batch(1000/2189), loss: 0.162180, imid loss: 0.042914, imid1 loss: 0.035667, cmid0 loss: 0.083599
Epoch (67), Batch(1200/2189), loss: 0.162347, imid loss: 0.043155, imid1 loss: 0.035238, cmid0 loss: 0.083954
Epoch (67), Batch(1400/2189), loss: 0.160739, imid loss: 0.042550, imid1 loss: 0.035043, cmid0 loss: 0.083145
Epoch (67), Batch(1600/2189), loss: 0.161312, imid loss: 0.042825, imid1 loss: 0.035512, cmid0 loss: 0.082975
Epoch (67), Batch(1800/2189), loss: 0.162015, imid loss: 0.042725, imid1 loss: 0.035931, cmid0 loss: 0.083358
Epoch (67), Batch(2000/2189), loss: 0.163556, imid loss: 0.042966, imid1 loss: 0.036262, cmid0 loss: 0.084328
Train 67, loss: 0.164511
Linear Accuracy : 0.896677471636953
Start training epoch: (68/100)
Epoch (68), Batch(0/2189), loss: 0.150594, imid loss: 0.016391, imid1 loss: 0.089980, cmid0 loss: 0.044222
Epoch (68), Batch(200/2189), loss: 0.153387, imid loss: 0.040423, imid1 loss: 0.033850, cmid0 loss: 0.079114
Epoch (68), Batch(400/2189), loss: 0.153660, imid loss: 0.040619, imid1 loss: 0.033630, cmid0 loss: 0.079411
Epoch (68), Batch(600/2189), loss: 0.154091, imid loss: 0.040931, imid1 loss: 0.032750, cmid0 loss: 0.080411
Epoch (68), Batch(800/2189), loss: 0.157593, imid loss: 0.042367, imid1 loss: 0.034106, cmid0 loss: 0.081120
Epoch (68), Batch(1000/2189), loss: 0.157829, imid loss: 0.042027, imid1 loss: 0.034078, cmid0 loss: 0.081724
Epoch (68), Batch(1200/2189), loss: 0.159813, imid loss: 0.042640, imid1 loss: 0.034547, cmid0 loss: 0.082626
Epoch (68), Batch(1400/2189), loss: 0.159600, imid loss: 0.042782, imid1 loss: 0.034565, cmid0 loss: 0.082253
Epoch (68), Batch(1600/2189), loss: 0.159983, imid loss: 0.042332, imid1 loss: 0.035022, cmid0 loss: 0.082629
Epoch (68), Batch(1800/2189), loss: 0.160320, imid loss: 0.041965, imid1 loss: 0.035126, cmid0 loss: 0.083229
Epoch (68), Batch(2000/2189), loss: 0.160514, imid loss: 0.041870, imid1 loss: 0.035595, cmid0 loss: 0.083049
Train 68, loss: 0.160671
Linear Accuracy : 0.8962722852512156
Start training epoch: (69/100)
Epoch (69), Batch(0/2189), loss: 0.073394, imid loss: 0.013557, imid1 loss: 0.030207, cmid0 loss: 0.029630
Epoch (69), Batch(200/2189), loss: 0.159945, imid loss: 0.041374, imid1 loss: 0.032590, cmid0 loss: 0.085982
Epoch (69), Batch(400/2189), loss: 0.165070, imid loss: 0.042010, imid1 loss: 0.035952, cmid0 loss: 0.087108
Epoch (69), Batch(600/2189), loss: 0.163228, imid loss: 0.042945, imid1 loss: 0.035453, cmid0 loss: 0.084829
Epoch (69), Batch(800/2189), loss: 0.159361, imid loss: 0.042671, imid1 loss: 0.034569, cmid0 loss: 0.082120
Epoch (69), Batch(1000/2189), loss: 0.159195, imid loss: 0.042512, imid1 loss: 0.034955, cmid0 loss: 0.081729
Epoch (69), Batch(1200/2189), loss: 0.160550, imid loss: 0.042591, imid1 loss: 0.035531, cmid0 loss: 0.082429
Epoch (69), Batch(1400/2189), loss: 0.161128, imid loss: 0.042368, imid1 loss: 0.036095, cmid0 loss: 0.082665
Epoch (69), Batch(1600/2189), loss: 0.160803, imid loss: 0.042596, imid1 loss: 0.035835, cmid0 loss: 0.082371
Epoch (69), Batch(1800/2189), loss: 0.160317, imid loss: 0.042392, imid1 loss: 0.035880, cmid0 loss: 0.082046
Epoch (69), Batch(2000/2189), loss: 0.159555, imid loss: 0.042336, imid1 loss: 0.035844, cmid0 loss: 0.081375
Train 69, loss: 0.159074
Linear Accuracy : 0.8970826580226904
Start training epoch: (70/100)
Epoch (70), Batch(0/2189), loss: 0.110838, imid loss: 0.025771, imid1 loss: 0.027230, cmid0 loss: 0.057838
Epoch (70), Batch(200/2189), loss: 0.156981, imid loss: 0.043035, imid1 loss: 0.031407, cmid0 loss: 0.082540
Epoch (70), Batch(400/2189), loss: 0.155533, imid loss: 0.041484, imid1 loss: 0.031820, cmid0 loss: 0.082229
Epoch (70), Batch(600/2189), loss: 0.154389, imid loss: 0.041131, imid1 loss: 0.032548, cmid0 loss: 0.080710
Epoch (70), Batch(800/2189), loss: 0.153463, imid loss: 0.040263, imid1 loss: 0.033359, cmid0 loss: 0.079841
Epoch (70), Batch(1000/2189), loss: 0.156461, imid loss: 0.041167, imid1 loss: 0.033694, cmid0 loss: 0.081599
Epoch (70), Batch(1200/2189), loss: 0.157803, imid loss: 0.041620, imid1 loss: 0.034087, cmid0 loss: 0.082097
Epoch (70), Batch(1400/2189), loss: 0.155897, imid loss: 0.041010, imid1 loss: 0.033861, cmid0 loss: 0.081026
Epoch (70), Batch(1600/2189), loss: 0.155028, imid loss: 0.040961, imid1 loss: 0.033933, cmid0 loss: 0.080134
Epoch (70), Batch(1800/2189), loss: 0.154372, imid loss: 0.040576, imid1 loss: 0.034240, cmid0 loss: 0.079556
Epoch (70), Batch(2000/2189), loss: 0.155157, imid loss: 0.040600, imid1 loss: 0.034596, cmid0 loss: 0.079961
Train 70, loss: 0.154480
Linear Accuracy : 0.8978930307941653
==> Saving...
Start training epoch: (71/100)
Epoch (71), Batch(0/2189), loss: 0.086721, imid loss: 0.010852, imid1 loss: 0.011247, cmid0 loss: 0.064622
Epoch (71), Batch(200/2189), loss: 0.155923, imid loss: 0.037661, imid1 loss: 0.033176, cmid0 loss: 0.085086
Epoch (71), Batch(400/2189), loss: 0.163386, imid loss: 0.040557, imid1 loss: 0.035966, cmid0 loss: 0.086863
Epoch (71), Batch(600/2189), loss: 0.159042, imid loss: 0.039609, imid1 loss: 0.035730, cmid0 loss: 0.083703
Epoch (71), Batch(800/2189), loss: 0.156657, imid loss: 0.040161, imid1 loss: 0.034387, cmid0 loss: 0.082109
Epoch (71), Batch(1000/2189), loss: 0.156365, imid loss: 0.040387, imid1 loss: 0.034225, cmid0 loss: 0.081753
Epoch (71), Batch(1200/2189), loss: 0.157808, imid loss: 0.040669, imid1 loss: 0.034954, cmid0 loss: 0.082185
Epoch (71), Batch(1400/2189), loss: 0.157813, imid loss: 0.040663, imid1 loss: 0.034795, cmid0 loss: 0.082356
Epoch (71), Batch(1600/2189), loss: 0.156149, imid loss: 0.040609, imid1 loss: 0.034266, cmid0 loss: 0.081273
Epoch (71), Batch(1800/2189), loss: 0.155899, imid loss: 0.040611, imid1 loss: 0.034001, cmid0 loss: 0.081287
Epoch (71), Batch(2000/2189), loss: 0.156576, imid loss: 0.040885, imid1 loss: 0.034135, cmid0 loss: 0.081556
Train 71, loss: 0.157187
Linear Accuracy : 0.9035656401944895
Start training epoch: (72/100)
Epoch (72), Batch(0/2189), loss: 0.044751, imid loss: 0.011935, imid1 loss: 0.007316, cmid0 loss: 0.025500
Epoch (72), Batch(200/2189), loss: 0.151550, imid loss: 0.039136, imid1 loss: 0.033273, cmid0 loss: 0.079142
Epoch (72), Batch(400/2189), loss: 0.150835, imid loss: 0.039831, imid1 loss: 0.032797, cmid0 loss: 0.078207
Epoch (72), Batch(600/2189), loss: 0.151681, imid loss: 0.039457, imid1 loss: 0.033755, cmid0 loss: 0.078469
Epoch (72), Batch(800/2189), loss: 0.148160, imid loss: 0.038217, imid1 loss: 0.033169, cmid0 loss: 0.076774
Epoch (72), Batch(1000/2189), loss: 0.149530, imid loss: 0.038708, imid1 loss: 0.033080, cmid0 loss: 0.077742
Epoch (72), Batch(1200/2189), loss: 0.147614, imid loss: 0.038609, imid1 loss: 0.032497, cmid0 loss: 0.076508
Epoch (72), Batch(1400/2189), loss: 0.150070, imid loss: 0.039114, imid1 loss: 0.032835, cmid0 loss: 0.078120
Epoch (72), Batch(1600/2189), loss: 0.149020, imid loss: 0.039040, imid1 loss: 0.032901, cmid0 loss: 0.077079
Epoch (72), Batch(1800/2189), loss: 0.149724, imid loss: 0.039237, imid1 loss: 0.033144, cmid0 loss: 0.077343
Epoch (72), Batch(2000/2189), loss: 0.148982, imid loss: 0.038954, imid1 loss: 0.032924, cmid0 loss: 0.077103
Train 72, loss: 0.149004
Linear Accuracy : 0.8987034035656402
Start training epoch: (73/100)
Epoch (73), Batch(0/2189), loss: 0.330347, imid loss: 0.162220, imid1 loss: 0.062039, cmid0 loss: 0.106089
Epoch (73), Batch(200/2189), loss: 0.138021, imid loss: 0.035884, imid1 loss: 0.032082, cmid0 loss: 0.070055
Epoch (73), Batch(400/2189), loss: 0.139468, imid loss: 0.036444, imid1 loss: 0.032865, cmid0 loss: 0.070159
Epoch (73), Batch(600/2189), loss: 0.143575, imid loss: 0.038070, imid1 loss: 0.032386, cmid0 loss: 0.073119
Epoch (73), Batch(800/2189), loss: 0.148783, imid loss: 0.039937, imid1 loss: 0.032783, cmid0 loss: 0.076063
Epoch (73), Batch(1000/2189), loss: 0.147316, imid loss: 0.039529, imid1 loss: 0.032477, cmid0 loss: 0.075310
Epoch (73), Batch(1200/2189), loss: 0.147422, imid loss: 0.039532, imid1 loss: 0.032349, cmid0 loss: 0.075540
Epoch (73), Batch(1400/2189), loss: 0.148004, imid loss: 0.039679, imid1 loss: 0.032147, cmid0 loss: 0.076178
Epoch (73), Batch(1600/2189), loss: 0.147479, imid loss: 0.039768, imid1 loss: 0.032077, cmid0 loss: 0.075634
Epoch (73), Batch(1800/2189), loss: 0.148017, imid loss: 0.040004, imid1 loss: 0.031891, cmid0 loss: 0.076122
Epoch (73), Batch(2000/2189), loss: 0.148480, imid loss: 0.039752, imid1 loss: 0.032385, cmid0 loss: 0.076343
Train 73, loss: 0.149004
Linear Accuracy : 0.8954619124797407
Start training epoch: (74/100)
Epoch (74), Batch(0/2189), loss: 0.342540, imid loss: 0.041366, imid1 loss: 0.020080, cmid0 loss: 0.281095
Epoch (74), Batch(200/2189), loss: 0.141050, imid loss: 0.036106, imid1 loss: 0.032280, cmid0 loss: 0.072664
Epoch (74), Batch(400/2189), loss: 0.145538, imid loss: 0.036016, imid1 loss: 0.033277, cmid0 loss: 0.076245
Epoch (74), Batch(600/2189), loss: 0.143608, imid loss: 0.035982, imid1 loss: 0.034157, cmid0 loss: 0.073469
Epoch (74), Batch(800/2189), loss: 0.146347, imid loss: 0.037512, imid1 loss: 0.034456, cmid0 loss: 0.074379
Epoch (74), Batch(1000/2189), loss: 0.148771, imid loss: 0.038298, imid1 loss: 0.033910, cmid0 loss: 0.076564
Epoch (74), Batch(1200/2189), loss: 0.146378, imid loss: 0.037796, imid1 loss: 0.033609, cmid0 loss: 0.074973
Epoch (74), Batch(1400/2189), loss: 0.144469, imid loss: 0.037412, imid1 loss: 0.032599, cmid0 loss: 0.074458
Epoch (74), Batch(1600/2189), loss: 0.143894, imid loss: 0.037129, imid1 loss: 0.032460, cmid0 loss: 0.074305
Epoch (74), Batch(1800/2189), loss: 0.144411, imid loss: 0.037327, imid1 loss: 0.032538, cmid0 loss: 0.074546
Epoch (74), Batch(2000/2189), loss: 0.145407, imid loss: 0.037281, imid1 loss: 0.032931, cmid0 loss: 0.075195
Train 74, loss: 0.145004
Linear Accuracy : 0.9027552674230146
Start training epoch: (75/100)
Epoch (75), Batch(0/2189), loss: 0.266390, imid loss: 0.096312, imid1 loss: 0.028609, cmid0 loss: 0.141469
Epoch (75), Batch(200/2189), loss: 0.130061, imid loss: 0.035043, imid1 loss: 0.028913, cmid0 loss: 0.066105
Epoch (75), Batch(400/2189), loss: 0.138415, imid loss: 0.036535, imid1 loss: 0.029970, cmid0 loss: 0.071910
Epoch (75), Batch(600/2189), loss: 0.140992, imid loss: 0.037888, imid1 loss: 0.030533, cmid0 loss: 0.072571
Epoch (75), Batch(800/2189), loss: 0.139344, imid loss: 0.036253, imid1 loss: 0.031124, cmid0 loss: 0.071966
Epoch (75), Batch(1000/2189), loss: 0.142864, imid loss: 0.037109, imid1 loss: 0.031344, cmid0 loss: 0.074411
Epoch (75), Batch(1200/2189), loss: 0.143440, imid loss: 0.037311, imid1 loss: 0.032092, cmid0 loss: 0.074037
Epoch (75), Batch(1400/2189), loss: 0.144028, imid loss: 0.037010, imid1 loss: 0.032203, cmid0 loss: 0.074815
Epoch (75), Batch(1600/2189), loss: 0.142303, imid loss: 0.036744, imid1 loss: 0.031691, cmid0 loss: 0.073868
Epoch (75), Batch(1800/2189), loss: 0.142011, imid loss: 0.036843, imid1 loss: 0.031619, cmid0 loss: 0.073549
Epoch (75), Batch(2000/2189), loss: 0.143009, imid loss: 0.037009, imid1 loss: 0.032090, cmid0 loss: 0.073910
Train 75, loss: 0.143308
Linear Accuracy : 0.9015397082658023
==> Saving...
Start training epoch: (76/100)
Epoch (76), Batch(0/2189), loss: 0.186918, imid loss: 0.019272, imid1 loss: 0.068008, cmid0 loss: 0.099637
Epoch (76), Batch(200/2189), loss: 0.153824, imid loss: 0.041033, imid1 loss: 0.030906, cmid0 loss: 0.081885
Epoch (76), Batch(400/2189), loss: 0.147212, imid loss: 0.039046, imid1 loss: 0.030877, cmid0 loss: 0.077289
Epoch (76), Batch(600/2189), loss: 0.140690, imid loss: 0.037715, imid1 loss: 0.029761, cmid0 loss: 0.073214
Epoch (76), Batch(800/2189), loss: 0.141056, imid loss: 0.037977, imid1 loss: 0.029070, cmid0 loss: 0.074009
Epoch (76), Batch(1000/2189), loss: 0.142417, imid loss: 0.038340, imid1 loss: 0.029573, cmid0 loss: 0.074504
Epoch (76), Batch(1200/2189), loss: 0.140896, imid loss: 0.038130, imid1 loss: 0.029641, cmid0 loss: 0.073124
Epoch (76), Batch(1400/2189), loss: 0.141375, imid loss: 0.037904, imid1 loss: 0.030235, cmid0 loss: 0.073236
Epoch (76), Batch(1600/2189), loss: 0.141531, imid loss: 0.037715, imid1 loss: 0.030295, cmid0 loss: 0.073520
Epoch (76), Batch(1800/2189), loss: 0.142881, imid loss: 0.037768, imid1 loss: 0.030515, cmid0 loss: 0.074598
Epoch (76), Batch(2000/2189), loss: 0.143195, imid loss: 0.038019, imid1 loss: 0.030506, cmid0 loss: 0.074670
Train 76, loss: 0.143526
Linear Accuracy : 0.9027552674230146
Start training epoch: (77/100)
Epoch (77), Batch(0/2189), loss: 0.043180, imid loss: 0.008091, imid1 loss: 0.010766, cmid0 loss: 0.024323
Epoch (77), Batch(200/2189), loss: 0.158399, imid loss: 0.040551, imid1 loss: 0.038003, cmid0 loss: 0.079846
Epoch (77), Batch(400/2189), loss: 0.146449, imid loss: 0.039599, imid1 loss: 0.032891, cmid0 loss: 0.073960
Epoch (77), Batch(600/2189), loss: 0.142855, imid loss: 0.039514, imid1 loss: 0.030884, cmid0 loss: 0.072457
Epoch (77), Batch(800/2189), loss: 0.142217, imid loss: 0.039369, imid1 loss: 0.031046, cmid0 loss: 0.071802
Epoch (77), Batch(1000/2189), loss: 0.141257, imid loss: 0.038369, imid1 loss: 0.030749, cmid0 loss: 0.072138
Epoch (77), Batch(1200/2189), loss: 0.142716, imid loss: 0.037768, imid1 loss: 0.032128, cmid0 loss: 0.072819
Epoch (77), Batch(1400/2189), loss: 0.141373, imid loss: 0.037334, imid1 loss: 0.032068, cmid0 loss: 0.071971
Epoch (77), Batch(1600/2189), loss: 0.140490, imid loss: 0.037219, imid1 loss: 0.031705, cmid0 loss: 0.071566
Epoch (77), Batch(1800/2189), loss: 0.140395, imid loss: 0.037338, imid1 loss: 0.031374, cmid0 loss: 0.071683
Epoch (77), Batch(2000/2189), loss: 0.139799, imid loss: 0.036808, imid1 loss: 0.031637, cmid0 loss: 0.071354
Train 77, loss: 0.139106
Linear Accuracy : 0.896677471636953
Start training epoch: (78/100)
Epoch (78), Batch(0/2189), loss: 0.181633, imid loss: 0.045860, imid1 loss: 0.024050, cmid0 loss: 0.111722
Epoch (78), Batch(200/2189), loss: 0.118585, imid loss: 0.029752, imid1 loss: 0.024127, cmid0 loss: 0.064706
Epoch (78), Batch(400/2189), loss: 0.124589, imid loss: 0.030518, imid1 loss: 0.027492, cmid0 loss: 0.066578
Epoch (78), Batch(600/2189), loss: 0.131337, imid loss: 0.033307, imid1 loss: 0.028885, cmid0 loss: 0.069145
Epoch (78), Batch(800/2189), loss: 0.131837, imid loss: 0.033362, imid1 loss: 0.029329, cmid0 loss: 0.069145
Epoch (78), Batch(1000/2189), loss: 0.133804, imid loss: 0.034260, imid1 loss: 0.029266, cmid0 loss: 0.070278
Epoch (78), Batch(1200/2189), loss: 0.134480, imid loss: 0.034354, imid1 loss: 0.030225, cmid0 loss: 0.069901
Epoch (78), Batch(1400/2189), loss: 0.135973, imid loss: 0.035411, imid1 loss: 0.030384, cmid0 loss: 0.070178
Epoch (78), Batch(1600/2189), loss: 0.137247, imid loss: 0.036038, imid1 loss: 0.030393, cmid0 loss: 0.070816
Epoch (78), Batch(1800/2189), loss: 0.137212, imid loss: 0.035925, imid1 loss: 0.030413, cmid0 loss: 0.070874
Epoch (78), Batch(2000/2189), loss: 0.137290, imid loss: 0.035780, imid1 loss: 0.030529, cmid0 loss: 0.070982
Train 78, loss: 0.136071
Linear Accuracy : 0.9059967585089141
==> Saving Best Model...
Start training epoch: (79/100)
Epoch (79), Batch(0/2189), loss: 0.393524, imid loss: 0.054973, imid1 loss: 0.074297, cmid0 loss: 0.264254
Epoch (79), Batch(200/2189), loss: 0.146953, imid loss: 0.039860, imid1 loss: 0.031310, cmid0 loss: 0.075784
Epoch (79), Batch(400/2189), loss: 0.140521, imid loss: 0.039130, imid1 loss: 0.029696, cmid0 loss: 0.071695
Epoch (79), Batch(600/2189), loss: 0.143494, imid loss: 0.039140, imid1 loss: 0.031028, cmid0 loss: 0.073326
Epoch (79), Batch(800/2189), loss: 0.144123, imid loss: 0.039462, imid1 loss: 0.030788, cmid0 loss: 0.073873
Epoch (79), Batch(1000/2189), loss: 0.146079, imid loss: 0.039444, imid1 loss: 0.031494, cmid0 loss: 0.075141
Epoch (79), Batch(1200/2189), loss: 0.146294, imid loss: 0.039121, imid1 loss: 0.031867, cmid0 loss: 0.075305
Epoch (79), Batch(1400/2189), loss: 0.143235, imid loss: 0.038509, imid1 loss: 0.030964, cmid0 loss: 0.073762
Epoch (79), Batch(1600/2189), loss: 0.141567, imid loss: 0.037816, imid1 loss: 0.031276, cmid0 loss: 0.072475
Epoch (79), Batch(1800/2189), loss: 0.140303, imid loss: 0.037584, imid1 loss: 0.030728, cmid0 loss: 0.071991
Epoch (79), Batch(2000/2189), loss: 0.140768, imid loss: 0.037294, imid1 loss: 0.031255, cmid0 loss: 0.072220
Train 79, loss: 0.140212
Linear Accuracy : 0.8999189627228525
Start training epoch: (80/100)
Epoch (80), Batch(0/2189), loss: 0.032275, imid loss: 0.010288, imid1 loss: 0.008216, cmid0 loss: 0.013772
Epoch (80), Batch(200/2189), loss: 0.141034, imid loss: 0.038695, imid1 loss: 0.027745, cmid0 loss: 0.074594
Epoch (80), Batch(400/2189), loss: 0.135787, imid loss: 0.036976, imid1 loss: 0.029972, cmid0 loss: 0.068839
Epoch (80), Batch(600/2189), loss: 0.135385, imid loss: 0.036423, imid1 loss: 0.029654, cmid0 loss: 0.069307
Epoch (80), Batch(800/2189), loss: 0.137510, imid loss: 0.037096, imid1 loss: 0.029779, cmid0 loss: 0.070635
Epoch (80), Batch(1000/2189), loss: 0.138725, imid loss: 0.038597, imid1 loss: 0.029254, cmid0 loss: 0.070875
Epoch (80), Batch(1200/2189), loss: 0.137285, imid loss: 0.037751, imid1 loss: 0.028755, cmid0 loss: 0.070779
Epoch (80), Batch(1400/2189), loss: 0.135796, imid loss: 0.037077, imid1 loss: 0.028729, cmid0 loss: 0.069990
Epoch (80), Batch(1600/2189), loss: 0.135976, imid loss: 0.036950, imid1 loss: 0.029056, cmid0 loss: 0.069970
Epoch (80), Batch(1800/2189), loss: 0.135484, imid loss: 0.036939, imid1 loss: 0.028924, cmid0 loss: 0.069620
Epoch (80), Batch(2000/2189), loss: 0.135107, imid loss: 0.036622, imid1 loss: 0.028967, cmid0 loss: 0.069518
Train 80, loss: 0.134259
Linear Accuracy : 0.899513776337115
==> Saving...
Start training epoch: (81/100)
Epoch (81), Batch(0/2189), loss: 0.044838, imid loss: 0.011737, imid1 loss: 0.010099, cmid0 loss: 0.023001
Epoch (81), Batch(200/2189), loss: 0.126655, imid loss: 0.035191, imid1 loss: 0.025959, cmid0 loss: 0.065505
Epoch (81), Batch(400/2189), loss: 0.132864, imid loss: 0.037503, imid1 loss: 0.027059, cmid0 loss: 0.068302
Epoch (81), Batch(600/2189), loss: 0.128967, imid loss: 0.036131, imid1 loss: 0.026454, cmid0 loss: 0.066382
Epoch (81), Batch(800/2189), loss: 0.130586, imid loss: 0.035141, imid1 loss: 0.026962, cmid0 loss: 0.068483
Epoch (81), Batch(1000/2189), loss: 0.131375, imid loss: 0.035389, imid1 loss: 0.027288, cmid0 loss: 0.068698
Epoch (81), Batch(1200/2189), loss: 0.134500, imid loss: 0.035770, imid1 loss: 0.027886, cmid0 loss: 0.070843
Epoch (81), Batch(1400/2189), loss: 0.135325, imid loss: 0.036006, imid1 loss: 0.028058, cmid0 loss: 0.071260
Epoch (81), Batch(1600/2189), loss: 0.133981, imid loss: 0.035828, imid1 loss: 0.027691, cmid0 loss: 0.070462
Epoch (81), Batch(1800/2189), loss: 0.134264, imid loss: 0.035546, imid1 loss: 0.028306, cmid0 loss: 0.070412
Epoch (81), Batch(2000/2189), loss: 0.134146, imid loss: 0.035391, imid1 loss: 0.028250, cmid0 loss: 0.070504
Train 81, loss: 0.133365
Linear Accuracy : 0.8999189627228525
Start training epoch: (82/100)
Epoch (82), Batch(0/2189), loss: 0.268909, imid loss: 0.107702, imid1 loss: 0.028775, cmid0 loss: 0.132432
Epoch (82), Batch(200/2189), loss: 0.123021, imid loss: 0.032932, imid1 loss: 0.026134, cmid0 loss: 0.063955
Epoch (82), Batch(400/2189), loss: 0.126917, imid loss: 0.033315, imid1 loss: 0.027780, cmid0 loss: 0.065821
Epoch (82), Batch(600/2189), loss: 0.131598, imid loss: 0.034567, imid1 loss: 0.028790, cmid0 loss: 0.068241
Epoch (82), Batch(800/2189), loss: 0.131845, imid loss: 0.034501, imid1 loss: 0.029327, cmid0 loss: 0.068018
Epoch (82), Batch(1000/2189), loss: 0.133100, imid loss: 0.035562, imid1 loss: 0.028957, cmid0 loss: 0.068581
Epoch (82), Batch(1200/2189), loss: 0.131471, imid loss: 0.035085, imid1 loss: 0.028600, cmid0 loss: 0.067786
Epoch (82), Batch(1400/2189), loss: 0.131542, imid loss: 0.035057, imid1 loss: 0.028922, cmid0 loss: 0.067563
Epoch (82), Batch(1600/2189), loss: 0.132405, imid loss: 0.035071, imid1 loss: 0.028970, cmid0 loss: 0.068364
Epoch (82), Batch(1800/2189), loss: 0.130905, imid loss: 0.034520, imid1 loss: 0.028946, cmid0 loss: 0.067438
Epoch (82), Batch(2000/2189), loss: 0.130302, imid loss: 0.034330, imid1 loss: 0.028786, cmid0 loss: 0.067186
Train 82, loss: 0.129587
Linear Accuracy : 0.9019448946515397
Start training epoch: (83/100)
Epoch (83), Batch(0/2189), loss: 0.129860, imid loss: 0.021612, imid1 loss: 0.047872, cmid0 loss: 0.060377
Epoch (83), Batch(200/2189), loss: 0.120423, imid loss: 0.032285, imid1 loss: 0.024183, cmid0 loss: 0.063955
Epoch (83), Batch(400/2189), loss: 0.122928, imid loss: 0.034628, imid1 loss: 0.025121, cmid0 loss: 0.063180
Epoch (83), Batch(600/2189), loss: 0.124385, imid loss: 0.033975, imid1 loss: 0.026425, cmid0 loss: 0.063986
Epoch (83), Batch(800/2189), loss: 0.125529, imid loss: 0.034234, imid1 loss: 0.027151, cmid0 loss: 0.064144
Epoch (83), Batch(1000/2189), loss: 0.124509, imid loss: 0.033946, imid1 loss: 0.026939, cmid0 loss: 0.063625
Epoch (83), Batch(1200/2189), loss: 0.124945, imid loss: 0.033819, imid1 loss: 0.027496, cmid0 loss: 0.063630
Epoch (83), Batch(1400/2189), loss: 0.124803, imid loss: 0.033643, imid1 loss: 0.027420, cmid0 loss: 0.063740
Epoch (83), Batch(1600/2189), loss: 0.125494, imid loss: 0.033277, imid1 loss: 0.027878, cmid0 loss: 0.064338
Epoch (83), Batch(1800/2189), loss: 0.125443, imid loss: 0.033117, imid1 loss: 0.027805, cmid0 loss: 0.064521
Epoch (83), Batch(2000/2189), loss: 0.128984, imid loss: 0.033975, imid1 loss: 0.028921, cmid0 loss: 0.066088
Train 83, loss: 0.128793
Linear Accuracy : 0.9023500810372771
Start training epoch: (84/100)
Epoch (84), Batch(0/2189), loss: 0.429589, imid loss: 0.164783, imid1 loss: 0.065762, cmid0 loss: 0.199044
Epoch (84), Batch(200/2189), loss: 0.128723, imid loss: 0.034541, imid1 loss: 0.029262, cmid0 loss: 0.064921
Epoch (84), Batch(400/2189), loss: 0.129555, imid loss: 0.035147, imid1 loss: 0.029400, cmid0 loss: 0.065008
Epoch (84), Batch(600/2189), loss: 0.127511, imid loss: 0.034668, imid1 loss: 0.027627, cmid0 loss: 0.065217
Epoch (84), Batch(800/2189), loss: 0.131080, imid loss: 0.035448, imid1 loss: 0.028710, cmid0 loss: 0.066922
Epoch (84), Batch(1000/2189), loss: 0.131511, imid loss: 0.035681, imid1 loss: 0.028749, cmid0 loss: 0.067082
Epoch (84), Batch(1200/2189), loss: 0.130969, imid loss: 0.034732, imid1 loss: 0.029101, cmid0 loss: 0.067136
Epoch (84), Batch(1400/2189), loss: 0.131138, imid loss: 0.034712, imid1 loss: 0.029110, cmid0 loss: 0.067316
Epoch (84), Batch(1600/2189), loss: 0.128510, imid loss: 0.033819, imid1 loss: 0.028784, cmid0 loss: 0.065907
Epoch (84), Batch(1800/2189), loss: 0.129655, imid loss: 0.033929, imid1 loss: 0.029310, cmid0 loss: 0.066416
Epoch (84), Batch(2000/2189), loss: 0.130649, imid loss: 0.034251, imid1 loss: 0.029549, cmid0 loss: 0.066849
Train 84, loss: 0.130422
Linear Accuracy : 0.9015397082658023
Start training epoch: (85/100)
Epoch (85), Batch(0/2189), loss: 0.197728, imid loss: 0.077931, imid1 loss: 0.067829, cmid0 loss: 0.051968
Epoch (85), Batch(200/2189), loss: 0.123862, imid loss: 0.035151, imid1 loss: 0.026196, cmid0 loss: 0.062515
Epoch (85), Batch(400/2189), loss: 0.125321, imid loss: 0.033805, imid1 loss: 0.027887, cmid0 loss: 0.063630
Epoch (85), Batch(600/2189), loss: 0.126548, imid loss: 0.033343, imid1 loss: 0.028838, cmid0 loss: 0.064367
Epoch (85), Batch(800/2189), loss: 0.130888, imid loss: 0.035069, imid1 loss: 0.028697, cmid0 loss: 0.067123
Epoch (85), Batch(1000/2189), loss: 0.129200, imid loss: 0.034394, imid1 loss: 0.028131, cmid0 loss: 0.066676
Epoch (85), Batch(1200/2189), loss: 0.131229, imid loss: 0.034946, imid1 loss: 0.028599, cmid0 loss: 0.067683
Epoch (85), Batch(1400/2189), loss: 0.133019, imid loss: 0.035172, imid1 loss: 0.029394, cmid0 loss: 0.068452
Epoch (85), Batch(1600/2189), loss: 0.132584, imid loss: 0.035219, imid1 loss: 0.029367, cmid0 loss: 0.067998
Epoch (85), Batch(1800/2189), loss: 0.133245, imid loss: 0.035553, imid1 loss: 0.029400, cmid0 loss: 0.068292
Epoch (85), Batch(2000/2189), loss: 0.133856, imid loss: 0.035483, imid1 loss: 0.029390, cmid0 loss: 0.068983
Train 85, loss: 0.132817
Linear Accuracy : 0.9011345218800648
==> Saving...
Start training epoch: (86/100)
Epoch (86), Batch(0/2189), loss: 0.030787, imid loss: 0.008763, imid1 loss: 0.009230, cmid0 loss: 0.012794
Epoch (86), Batch(200/2189), loss: 0.130005, imid loss: 0.034073, imid1 loss: 0.026870, cmid0 loss: 0.069062
Epoch (86), Batch(400/2189), loss: 0.129321, imid loss: 0.034454, imid1 loss: 0.027316, cmid0 loss: 0.067551
Epoch (86), Batch(600/2189), loss: 0.128300, imid loss: 0.034692, imid1 loss: 0.027332, cmid0 loss: 0.066276
Epoch (86), Batch(800/2189), loss: 0.125882, imid loss: 0.034082, imid1 loss: 0.026240, cmid0 loss: 0.065561
Epoch (86), Batch(1000/2189), loss: 0.125925, imid loss: 0.033854, imid1 loss: 0.026925, cmid0 loss: 0.065147
Epoch (86), Batch(1200/2189), loss: 0.128657, imid loss: 0.034734, imid1 loss: 0.027928, cmid0 loss: 0.065996
Epoch (86), Batch(1400/2189), loss: 0.128254, imid loss: 0.034697, imid1 loss: 0.027933, cmid0 loss: 0.065624
Epoch (86), Batch(1600/2189), loss: 0.129646, imid loss: 0.034973, imid1 loss: 0.028155, cmid0 loss: 0.066518
Epoch (86), Batch(1800/2189), loss: 0.129170, imid loss: 0.034655, imid1 loss: 0.027978, cmid0 loss: 0.066537
Epoch (86), Batch(2000/2189), loss: 0.130001, imid loss: 0.035142, imid1 loss: 0.027892, cmid0 loss: 0.066967
Train 86, loss: 0.129819
Linear Accuracy : 0.9019448946515397
Start training epoch: (87/100)
Epoch (87), Batch(0/2189), loss: 0.251356, imid loss: 0.025044, imid1 loss: 0.101534, cmid0 loss: 0.124777
Epoch (87), Batch(200/2189), loss: 0.126336, imid loss: 0.033766, imid1 loss: 0.028029, cmid0 loss: 0.064541
Epoch (87), Batch(400/2189), loss: 0.121654, imid loss: 0.033144, imid1 loss: 0.025913, cmid0 loss: 0.062597
Epoch (87), Batch(600/2189), loss: 0.124970, imid loss: 0.033818, imid1 loss: 0.027133, cmid0 loss: 0.064019
Epoch (87), Batch(800/2189), loss: 0.126667, imid loss: 0.034015, imid1 loss: 0.027358, cmid0 loss: 0.065295
Epoch (87), Batch(1000/2189), loss: 0.128551, imid loss: 0.034587, imid1 loss: 0.027834, cmid0 loss: 0.066131
Epoch (87), Batch(1200/2189), loss: 0.127017, imid loss: 0.034102, imid1 loss: 0.027397, cmid0 loss: 0.065518
Epoch (87), Batch(1400/2189), loss: 0.126452, imid loss: 0.033891, imid1 loss: 0.027525, cmid0 loss: 0.065036
Epoch (87), Batch(1600/2189), loss: 0.126897, imid loss: 0.033717, imid1 loss: 0.027599, cmid0 loss: 0.065581
Epoch (87), Batch(1800/2189), loss: 0.127413, imid loss: 0.033709, imid1 loss: 0.027905, cmid0 loss: 0.065799
Epoch (87), Batch(2000/2189), loss: 0.126359, imid loss: 0.033255, imid1 loss: 0.027810, cmid0 loss: 0.065294
Train 87, loss: 0.125569
Linear Accuracy : 0.9011345218800648
Start training epoch: (88/100)
Epoch (88), Batch(0/2189), loss: 0.120203, imid loss: 0.045173, imid1 loss: 0.024447, cmid0 loss: 0.050583
Epoch (88), Batch(200/2189), loss: 0.127211, imid loss: 0.032878, imid1 loss: 0.028548, cmid0 loss: 0.065786
Epoch (88), Batch(400/2189), loss: 0.123587, imid loss: 0.032108, imid1 loss: 0.028275, cmid0 loss: 0.063204
Epoch (88), Batch(600/2189), loss: 0.124703, imid loss: 0.032827, imid1 loss: 0.027496, cmid0 loss: 0.064380
Epoch (88), Batch(800/2189), loss: 0.124416, imid loss: 0.032529, imid1 loss: 0.026989, cmid0 loss: 0.064899
Epoch (88), Batch(1000/2189), loss: 0.126506, imid loss: 0.032673, imid1 loss: 0.027262, cmid0 loss: 0.066571
Epoch (88), Batch(1200/2189), loss: 0.126800, imid loss: 0.032600, imid1 loss: 0.027640, cmid0 loss: 0.066561
Epoch (88), Batch(1400/2189), loss: 0.125981, imid loss: 0.032834, imid1 loss: 0.027374, cmid0 loss: 0.065773
Epoch (88), Batch(1600/2189), loss: 0.124814, imid loss: 0.032716, imid1 loss: 0.027305, cmid0 loss: 0.064793
Epoch (88), Batch(1800/2189), loss: 0.124573, imid loss: 0.033023, imid1 loss: 0.027266, cmid0 loss: 0.064284
Epoch (88), Batch(2000/2189), loss: 0.125119, imid loss: 0.032972, imid1 loss: 0.027202, cmid0 loss: 0.064945
Train 88, loss: 0.124578
Linear Accuracy : 0.9011345218800648
Start training epoch: (89/100)
Epoch (89), Batch(0/2189), loss: 0.100512, imid loss: 0.049120, imid1 loss: 0.016467, cmid0 loss: 0.034925
Epoch (89), Batch(200/2189), loss: 0.116712, imid loss: 0.032112, imid1 loss: 0.021927, cmid0 loss: 0.062674
Epoch (89), Batch(400/2189), loss: 0.123995, imid loss: 0.032731, imid1 loss: 0.025854, cmid0 loss: 0.065410
Epoch (89), Batch(600/2189), loss: 0.120177, imid loss: 0.031226, imid1 loss: 0.025461, cmid0 loss: 0.063490
Epoch (89), Batch(800/2189), loss: 0.120673, imid loss: 0.031590, imid1 loss: 0.025847, cmid0 loss: 0.063237
Epoch (89), Batch(1000/2189), loss: 0.124300, imid loss: 0.032298, imid1 loss: 0.027094, cmid0 loss: 0.064907
Epoch (89), Batch(1200/2189), loss: 0.124841, imid loss: 0.032614, imid1 loss: 0.027021, cmid0 loss: 0.065206
Epoch (89), Batch(1400/2189), loss: 0.124350, imid loss: 0.032286, imid1 loss: 0.027081, cmid0 loss: 0.064984
Epoch (89), Batch(1600/2189), loss: 0.124747, imid loss: 0.032458, imid1 loss: 0.027192, cmid0 loss: 0.065097
Epoch (89), Batch(1800/2189), loss: 0.124704, imid loss: 0.032314, imid1 loss: 0.027053, cmid0 loss: 0.065336
Epoch (89), Batch(2000/2189), loss: 0.124516, imid loss: 0.032091, imid1 loss: 0.027034, cmid0 loss: 0.065391
Train 89, loss: 0.123751
Linear Accuracy : 0.8962722852512156
Start training epoch: (90/100)
Epoch (90), Batch(0/2189), loss: 0.084440, imid loss: 0.024578, imid1 loss: 0.019808, cmid0 loss: 0.040053
Epoch (90), Batch(200/2189), loss: 0.126972, imid loss: 0.037234, imid1 loss: 0.025897, cmid0 loss: 0.063841
Epoch (90), Batch(400/2189), loss: 0.125470, imid loss: 0.034455, imid1 loss: 0.026495, cmid0 loss: 0.064521
Epoch (90), Batch(600/2189), loss: 0.127005, imid loss: 0.035081, imid1 loss: 0.027189, cmid0 loss: 0.064735
Epoch (90), Batch(800/2189), loss: 0.126867, imid loss: 0.034724, imid1 loss: 0.027786, cmid0 loss: 0.064357
Epoch (90), Batch(1000/2189), loss: 0.128778, imid loss: 0.034990, imid1 loss: 0.027816, cmid0 loss: 0.065971
Epoch (90), Batch(1200/2189), loss: 0.127605, imid loss: 0.034452, imid1 loss: 0.027374, cmid0 loss: 0.065778
Epoch (90), Batch(1400/2189), loss: 0.127551, imid loss: 0.034051, imid1 loss: 0.027427, cmid0 loss: 0.066072
Epoch (90), Batch(1600/2189), loss: 0.126927, imid loss: 0.034147, imid1 loss: 0.026982, cmid0 loss: 0.065798
Epoch (90), Batch(1800/2189), loss: 0.125945, imid loss: 0.033677, imid1 loss: 0.026825, cmid0 loss: 0.065443
Epoch (90), Batch(2000/2189), loss: 0.124669, imid loss: 0.033245, imid1 loss: 0.026724, cmid0 loss: 0.064700
Train 90, loss: 0.124306
Linear Accuracy : 0.9015397082658023
==> Saving...
Start training epoch: (91/100)
Epoch (91), Batch(0/2189), loss: 0.049039, imid loss: 0.009158, imid1 loss: 0.013550, cmid0 loss: 0.026332
Epoch (91), Batch(200/2189), loss: 0.126557, imid loss: 0.035865, imid1 loss: 0.025077, cmid0 loss: 0.065615
Epoch (91), Batch(400/2189), loss: 0.128864, imid loss: 0.035040, imid1 loss: 0.027752, cmid0 loss: 0.066073
Epoch (91), Batch(600/2189), loss: 0.126102, imid loss: 0.033943, imid1 loss: 0.027569, cmid0 loss: 0.064591
Epoch (91), Batch(800/2189), loss: 0.123836, imid loss: 0.033762, imid1 loss: 0.027076, cmid0 loss: 0.062998
Epoch (91), Batch(1000/2189), loss: 0.121640, imid loss: 0.033571, imid1 loss: 0.026032, cmid0 loss: 0.062037
Epoch (91), Batch(1200/2189), loss: 0.121875, imid loss: 0.033430, imid1 loss: 0.026063, cmid0 loss: 0.062382
Epoch (91), Batch(1400/2189), loss: 0.122544, imid loss: 0.033736, imid1 loss: 0.026023, cmid0 loss: 0.062785
Epoch (91), Batch(1600/2189), loss: 0.122539, imid loss: 0.033558, imid1 loss: 0.025993, cmid0 loss: 0.062988
Epoch (91), Batch(1800/2189), loss: 0.122776, imid loss: 0.033279, imid1 loss: 0.026151, cmid0 loss: 0.063347
Epoch (91), Batch(2000/2189), loss: 0.122691, imid loss: 0.033553, imid1 loss: 0.026163, cmid0 loss: 0.062975
Train 91, loss: 0.123182
Linear Accuracy : 0.899513776337115
Start training epoch: (92/100)
Epoch (92), Batch(0/2189), loss: 0.350835, imid loss: 0.021567, imid1 loss: 0.068011, cmid0 loss: 0.261256
Epoch (92), Batch(200/2189), loss: 0.114462, imid loss: 0.031872, imid1 loss: 0.024297, cmid0 loss: 0.058292
Epoch (92), Batch(400/2189), loss: 0.117069, imid loss: 0.031415, imid1 loss: 0.027357, cmid0 loss: 0.058297
Epoch (92), Batch(600/2189), loss: 0.117593, imid loss: 0.032125, imid1 loss: 0.025682, cmid0 loss: 0.059786
Epoch (92), Batch(800/2189), loss: 0.117678, imid loss: 0.032098, imid1 loss: 0.025903, cmid0 loss: 0.059677
Epoch (92), Batch(1000/2189), loss: 0.119894, imid loss: 0.032718, imid1 loss: 0.026003, cmid0 loss: 0.061174
Epoch (92), Batch(1200/2189), loss: 0.119973, imid loss: 0.032576, imid1 loss: 0.025741, cmid0 loss: 0.061656
Epoch (92), Batch(1400/2189), loss: 0.119679, imid loss: 0.032292, imid1 loss: 0.026133, cmid0 loss: 0.061254
Epoch (92), Batch(1600/2189), loss: 0.119930, imid loss: 0.032314, imid1 loss: 0.026334, cmid0 loss: 0.061282
Epoch (92), Batch(1800/2189), loss: 0.120902, imid loss: 0.032520, imid1 loss: 0.026616, cmid0 loss: 0.061766
Epoch (92), Batch(2000/2189), loss: 0.121190, imid loss: 0.032782, imid1 loss: 0.026599, cmid0 loss: 0.061810
Train 92, loss: 0.121189
Linear Accuracy : 0.9015397082658023
Start training epoch: (93/100)
Epoch (93), Batch(0/2189), loss: 0.239840, imid loss: 0.026350, imid1 loss: 0.076218, cmid0 loss: 0.137272
Epoch (93), Batch(200/2189), loss: 0.122322, imid loss: 0.033057, imid1 loss: 0.026560, cmid0 loss: 0.062704
Epoch (93), Batch(400/2189), loss: 0.125498, imid loss: 0.034768, imid1 loss: 0.026919, cmid0 loss: 0.063811
Epoch (93), Batch(600/2189), loss: 0.128641, imid loss: 0.035282, imid1 loss: 0.028028, cmid0 loss: 0.065331
Epoch (93), Batch(800/2189), loss: 0.124543, imid loss: 0.034111, imid1 loss: 0.027059, cmid0 loss: 0.063372
Epoch (93), Batch(1000/2189), loss: 0.121251, imid loss: 0.033187, imid1 loss: 0.026189, cmid0 loss: 0.061875
Epoch (93), Batch(1200/2189), loss: 0.121063, imid loss: 0.033361, imid1 loss: 0.025947, cmid0 loss: 0.061754
Epoch (93), Batch(1400/2189), loss: 0.120833, imid loss: 0.033023, imid1 loss: 0.025834, cmid0 loss: 0.061976
Epoch (93), Batch(1600/2189), loss: 0.121609, imid loss: 0.032784, imid1 loss: 0.026274, cmid0 loss: 0.062552
Epoch (93), Batch(1800/2189), loss: 0.121879, imid loss: 0.032928, imid1 loss: 0.025997, cmid0 loss: 0.062954
Epoch (93), Batch(2000/2189), loss: 0.120564, imid loss: 0.032642, imid1 loss: 0.025446, cmid0 loss: 0.062475
Train 93, loss: 0.120264
Linear Accuracy : 0.9043760129659644
Start training epoch: (94/100)
Epoch (94), Batch(0/2189), loss: 0.232035, imid loss: 0.095999, imid1 loss: 0.006695, cmid0 loss: 0.129341
Epoch (94), Batch(200/2189), loss: 0.124716, imid loss: 0.034280, imid1 loss: 0.024789, cmid0 loss: 0.065647
Epoch (94), Batch(400/2189), loss: 0.122039, imid loss: 0.035096, imid1 loss: 0.024412, cmid0 loss: 0.062531
Epoch (94), Batch(600/2189), loss: 0.122130, imid loss: 0.035209, imid1 loss: 0.024130, cmid0 loss: 0.062790
Epoch (94), Batch(800/2189), loss: 0.120498, imid loss: 0.033948, imid1 loss: 0.024189, cmid0 loss: 0.062362
Epoch (94), Batch(1000/2189), loss: 0.120236, imid loss: 0.033391, imid1 loss: 0.025289, cmid0 loss: 0.061556
Epoch (94), Batch(1200/2189), loss: 0.120203, imid loss: 0.032813, imid1 loss: 0.025591, cmid0 loss: 0.061799
Epoch (94), Batch(1400/2189), loss: 0.121330, imid loss: 0.033385, imid1 loss: 0.025755, cmid0 loss: 0.062191
Epoch (94), Batch(1600/2189), loss: 0.121253, imid loss: 0.033225, imid1 loss: 0.026115, cmid0 loss: 0.061912
Epoch (94), Batch(1800/2189), loss: 0.121534, imid loss: 0.032926, imid1 loss: 0.026405, cmid0 loss: 0.062203
Epoch (94), Batch(2000/2189), loss: 0.122532, imid loss: 0.033141, imid1 loss: 0.026757, cmid0 loss: 0.062634
Train 94, loss: 0.122343
Linear Accuracy : 0.9011345218800648
Start training epoch: (95/100)
Epoch (95), Batch(0/2189), loss: 0.082636, imid loss: 0.027039, imid1 loss: 0.009440, cmid0 loss: 0.046157
Epoch (95), Batch(200/2189), loss: 0.126968, imid loss: 0.033073, imid1 loss: 0.029685, cmid0 loss: 0.064210
Epoch (95), Batch(400/2189), loss: 0.124131, imid loss: 0.032015, imid1 loss: 0.029983, cmid0 loss: 0.062132
Epoch (95), Batch(600/2189), loss: 0.123185, imid loss: 0.032295, imid1 loss: 0.028167, cmid0 loss: 0.062724
Epoch (95), Batch(800/2189), loss: 0.123158, imid loss: 0.032305, imid1 loss: 0.027584, cmid0 loss: 0.063270
Epoch (95), Batch(1000/2189), loss: 0.123182, imid loss: 0.032460, imid1 loss: 0.027179, cmid0 loss: 0.063543
Epoch (95), Batch(1200/2189), loss: 0.125139, imid loss: 0.033115, imid1 loss: 0.027422, cmid0 loss: 0.064603
Epoch (95), Batch(1400/2189), loss: 0.125116, imid loss: 0.033365, imid1 loss: 0.027116, cmid0 loss: 0.064634
Epoch (95), Batch(1600/2189), loss: 0.123979, imid loss: 0.032713, imid1 loss: 0.027177, cmid0 loss: 0.064089
Epoch (95), Batch(1800/2189), loss: 0.122864, imid loss: 0.032623, imid1 loss: 0.026837, cmid0 loss: 0.063404
Epoch (95), Batch(2000/2189), loss: 0.121656, imid loss: 0.032246, imid1 loss: 0.026618, cmid0 loss: 0.062792
Train 95, loss: 0.121469
Linear Accuracy : 0.9043760129659644
==> Saving...
Start training epoch: (96/100)
Epoch (96), Batch(0/2189), loss: 0.099615, imid loss: 0.050823, imid1 loss: 0.005757, cmid0 loss: 0.043035
Epoch (96), Batch(200/2189), loss: 0.124301, imid loss: 0.033286, imid1 loss: 0.026961, cmid0 loss: 0.064054
Epoch (96), Batch(400/2189), loss: 0.122239, imid loss: 0.031814, imid1 loss: 0.026876, cmid0 loss: 0.063549
Epoch (96), Batch(600/2189), loss: 0.119055, imid loss: 0.031492, imid1 loss: 0.025648, cmid0 loss: 0.061915
Epoch (96), Batch(800/2189), loss: 0.121027, imid loss: 0.032526, imid1 loss: 0.025283, cmid0 loss: 0.063217
Epoch (96), Batch(1000/2189), loss: 0.124085, imid loss: 0.033248, imid1 loss: 0.026441, cmid0 loss: 0.064396
Epoch (96), Batch(1200/2189), loss: 0.124269, imid loss: 0.033120, imid1 loss: 0.026374, cmid0 loss: 0.064775
Epoch (96), Batch(1400/2189), loss: 0.123283, imid loss: 0.032816, imid1 loss: 0.026485, cmid0 loss: 0.063982
Epoch (96), Batch(1600/2189), loss: 0.123440, imid loss: 0.032506, imid1 loss: 0.026799, cmid0 loss: 0.064135
Epoch (96), Batch(1800/2189), loss: 0.122970, imid loss: 0.032676, imid1 loss: 0.026264, cmid0 loss: 0.064031
Epoch (96), Batch(2000/2189), loss: 0.123369, imid loss: 0.032716, imid1 loss: 0.026583, cmid0 loss: 0.064069
Train 96, loss: 0.122383
Linear Accuracy : 0.9039708265802269
Start training epoch: (97/100)
Epoch (97), Batch(0/2189), loss: 0.041229, imid loss: 0.007415, imid1 loss: 0.015211, cmid0 loss: 0.018602
Epoch (97), Batch(200/2189), loss: 0.114087, imid loss: 0.033628, imid1 loss: 0.021798, cmid0 loss: 0.058662
Epoch (97), Batch(400/2189), loss: 0.115876, imid loss: 0.032692, imid1 loss: 0.024023, cmid0 loss: 0.059161
Epoch (97), Batch(600/2189), loss: 0.118210, imid loss: 0.032501, imid1 loss: 0.025478, cmid0 loss: 0.060231
Epoch (97), Batch(800/2189), loss: 0.117239, imid loss: 0.031989, imid1 loss: 0.024515, cmid0 loss: 0.060734
Epoch (97), Batch(1000/2189), loss: 0.116078, imid loss: 0.031613, imid1 loss: 0.024481, cmid0 loss: 0.059985
Epoch (97), Batch(1200/2189), loss: 0.116289, imid loss: 0.031358, imid1 loss: 0.024692, cmid0 loss: 0.060239
Epoch (97), Batch(1400/2189), loss: 0.118494, imid loss: 0.031875, imid1 loss: 0.024733, cmid0 loss: 0.061886
Epoch (97), Batch(1600/2189), loss: 0.120282, imid loss: 0.032041, imid1 loss: 0.025353, cmid0 loss: 0.062888
Epoch (97), Batch(1800/2189), loss: 0.120360, imid loss: 0.031925, imid1 loss: 0.025479, cmid0 loss: 0.062957
Epoch (97), Batch(2000/2189), loss: 0.119867, imid loss: 0.031915, imid1 loss: 0.025392, cmid0 loss: 0.062560
Train 97, loss: 0.119427
Linear Accuracy : 0.903160453808752
Start training epoch: (98/100)
Epoch (98), Batch(0/2189), loss: 0.090101, imid loss: 0.021768, imid1 loss: 0.011417, cmid0 loss: 0.056916
Epoch (98), Batch(200/2189), loss: 0.121067, imid loss: 0.031168, imid1 loss: 0.027463, cmid0 loss: 0.062436
Epoch (98), Batch(400/2189), loss: 0.118117, imid loss: 0.030310, imid1 loss: 0.026401, cmid0 loss: 0.061407
Epoch (98), Batch(600/2189), loss: 0.119777, imid loss: 0.030480, imid1 loss: 0.026789, cmid0 loss: 0.062508
Epoch (98), Batch(800/2189), loss: 0.118410, imid loss: 0.030053, imid1 loss: 0.026868, cmid0 loss: 0.061488
Epoch (98), Batch(1000/2189), loss: 0.118289, imid loss: 0.030567, imid1 loss: 0.026560, cmid0 loss: 0.061162
Epoch (98), Batch(1200/2189), loss: 0.118298, imid loss: 0.030793, imid1 loss: 0.026279, cmid0 loss: 0.061225
Epoch (98), Batch(1400/2189), loss: 0.117859, imid loss: 0.030428, imid1 loss: 0.026532, cmid0 loss: 0.060900
Epoch (98), Batch(1600/2189), loss: 0.118215, imid loss: 0.030483, imid1 loss: 0.026664, cmid0 loss: 0.061068
Epoch (98), Batch(1800/2189), loss: 0.118414, imid loss: 0.030459, imid1 loss: 0.026822, cmid0 loss: 0.061132
Epoch (98), Batch(2000/2189), loss: 0.118417, imid loss: 0.030648, imid1 loss: 0.026728, cmid0 loss: 0.061041
Train 98, loss: 0.118630
Linear Accuracy : 0.9023500810372771
Start training epoch: (99/100)
Epoch (99), Batch(0/2189), loss: 0.103803, imid loss: 0.020805, imid1 loss: 0.013470, cmid0 loss: 0.069528
Epoch (99), Batch(200/2189), loss: 0.120805, imid loss: 0.031324, imid1 loss: 0.027993, cmid0 loss: 0.061488
Epoch (99), Batch(400/2189), loss: 0.125650, imid loss: 0.034597, imid1 loss: 0.026902, cmid0 loss: 0.064152
Epoch (99), Batch(600/2189), loss: 0.125319, imid loss: 0.033216, imid1 loss: 0.027569, cmid0 loss: 0.064534
Epoch (99), Batch(800/2189), loss: 0.126089, imid loss: 0.034439, imid1 loss: 0.026643, cmid0 loss: 0.065007
Epoch (99), Batch(1000/2189), loss: 0.126551, imid loss: 0.034132, imid1 loss: 0.026615, cmid0 loss: 0.065804
Epoch (99), Batch(1200/2189), loss: 0.126745, imid loss: 0.034423, imid1 loss: 0.026372, cmid0 loss: 0.065950
Epoch (99), Batch(1400/2189), loss: 0.125686, imid loss: 0.033971, imid1 loss: 0.026624, cmid0 loss: 0.065091
Epoch (99), Batch(1600/2189), loss: 0.126451, imid loss: 0.034162, imid1 loss: 0.027051, cmid0 loss: 0.065238
Epoch (99), Batch(1800/2189), loss: 0.125337, imid loss: 0.033947, imid1 loss: 0.026593, cmid0 loss: 0.064797
Epoch (99), Batch(2000/2189), loss: 0.124591, imid loss: 0.033869, imid1 loss: 0.026475, cmid0 loss: 0.064247
Train 99, loss: 0.124591
Linear Accuracy : 0.9035656401944895
==> Saving Last Model...